"""
Validation Extension with Interactive Chat Interface
Cho ph√©p ng∆∞·ªùi d√πng chat v·ªõi agent ngay trong tab Questions v√† Scenarios
H·ªñ TR·ª¢ QUERY NHI·ªÄU B·∫¢NG (Multi-Table) V√Ä STREAMING
"""

import streamlit as st
import pandas as pd
from typing import Dict, Any, List, Optional, Generator
from datetime import datetime
from pathlib import Path
import sqlite3
import re
import logging
import json

logger = logging.getLogger(__name__)


# ============================================================================
# SQL Query Tool (Single Table - GI·ªÆ NGUY√äN ƒê·ªÇ BACKWARD COMPATIBLE)
# ============================================================================

class SQLQueryTool:
    """Tool to execute SQL queries - thread-safe for Streamlit"""

    def __init__(self, db_path: str, df: pd.DataFrame, table_name: str = "data"):
        self.db_path = db_path
        self.table_name = table_name
        self.df_hash = hash(str(df.values.tobytes()))
        self._create_database(df)

    def _create_database(self, df: pd.DataFrame):
        """Create/recreate database with data"""
        try:
            if hasattr(self, 'conn') and self.conn:
                self.conn.close()
            self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
            df.to_sql(self.table_name, self.conn, if_exists='replace', index=False)
        except Exception as e:
            raise RuntimeError(f"Failed to create database: {str(e)}")

    def _ensure_connection(self):
        """Ensure connection is valid, recreate if needed"""
        try:
            if not self.conn:
                self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
            self.conn.execute("SELECT 1")
        except:
            self.conn = sqlite3.connect(self.db_path, check_same_thread=False)

    def execute_query(self, query: str):
        try:
            if not query.upper().strip().startswith('SELECT'):
                return pd.DataFrame(), "Only SELECT allowed"
            self._ensure_connection()
            result_df = pd.read_sql_query(query, self.conn)
            return result_df, None
        except Exception as e:
            return pd.DataFrame(), f"Error: {str(e)}"

    def get_schema_info(self):
        try:
            self._ensure_connection()
            cursor = self.conn.cursor()
            cursor.execute(f"PRAGMA table_info({self.table_name})")
            columns = cursor.fetchall()
            cursor.execute(f"SELECT COUNT(*) FROM {self.table_name}")
            row_count = cursor.fetchone()[0]
            return {
                "table_name": self.table_name,
                "columns": [{"name": col[1], "type": col[2]} for col in columns],
                "row_count": row_count
            }
        except Exception as e:
            return {"error": str(e)}

    def close(self):
        if hasattr(self, 'conn') and self.conn:
            self.conn.close()


# ============================================================================
# Multi-Table SQL Query Tool - H·ªñ TR·ª¢ QUERY NHI·ªÄU B·∫¢NG
# ============================================================================

class MultiTableSQLQueryTool:
    """
    SQL Query Tool h·ªó tr·ª£ nhi·ªÅu b·∫£ng.
    Cho ph√©p ng∆∞·ªùi d√πng query tr√™n nhi·ªÅu DataFrame/b·∫£ng c√πng l√∫c.
    """
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.tables: Dict[str, Dict[str, Any]] = {}
        self.conn = None
        self._create_connection()
    
    def _create_connection(self):
        try:
            if self.conn:
                self.conn.close()
            self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        except Exception as e:
            raise RuntimeError(f"Failed to create database connection: {str(e)}")
    
    def _ensure_connection(self):
        try:
            if not self.conn:
                self._create_connection()
            self.conn.execute("SELECT 1")
        except:
            self._create_connection()
    
    def _sanitize_table_name(self, name: str) -> str:
        """Sanitize table name for SQL"""
        safe_name = re.sub(r'[^\w]', '_', str(name))
        if safe_name and safe_name[0].isdigit():
            safe_name = 't_' + safe_name
        return safe_name or 'data'
    
    def add_table(self, table_name: str, df: pd.DataFrame, schema_info: Dict = None) -> bool:
        """Th√™m ho·∫∑c c·∫≠p nh·∫≠t m·ªôt b·∫£ng v√†o database"""
        try:
            safe_name = self._sanitize_table_name(table_name)
            df_hash = hash(str(df.values.tobytes()))
            
            self._ensure_connection()
            df.to_sql(safe_name, self.conn, if_exists='replace', index=False)
            
            self.tables[safe_name] = {
                "df_hash": df_hash,
                "columns": list(df.columns),
                "row_count": len(df),
                "original_name": table_name,
                "schema_info": schema_info or {}
            }
            return True
        except Exception as e:
            logger.error(f"Failed to add table '{table_name}': {str(e)}")
            return False
    
    def remove_table(self, table_name: str) -> bool:
        """X√≥a m·ªôt b·∫£ng kh·ªèi database"""
        try:
            safe_name = self._sanitize_table_name(table_name)
            if safe_name not in self.tables:
                return False
            self._ensure_connection()
            self.conn.execute(f"DROP TABLE IF EXISTS [{safe_name}]")
            del self.tables[safe_name]
            return True
        except Exception as e:
            return False
    
    def execute_query(self, query: str) -> tuple:
        """Th·ª±c thi SQL query"""
        try:
            if not query.upper().strip().startswith('SELECT'):
                return pd.DataFrame(), "Ch·ªâ cho ph√©p SELECT queries"
            self._ensure_connection()
            result_df = pd.read_sql_query(query, self.conn)
            return result_df, None
        except Exception as e:
            return pd.DataFrame(), f"SQL Error: {str(e)}"
    
    def get_tables_info(self) -> Dict[str, Any]:
        """L·∫•y th√¥ng tin t·∫•t c·∫£ c√°c b·∫£ng"""
        return {
            "tables": [
                {
                    "name": name,
                    "original_name": info.get("original_name", name),
                    "columns": info.get("columns", []),
                    "row_count": info.get("row_count", 0),
                }
                for name, info in self.tables.items()
            ],
            "total_tables": len(self.tables)
        }
    
    def get_schema_info(self) -> Dict[str, Any]:
        """L·∫•y th√¥ng tin schema cho t·∫•t c·∫£ c√°c b·∫£ng (t∆∞∆°ng th√≠ch v·ªõi SQLQueryTool)"""
        return self.get_tables_info()
    
    def close(self):
        if self.conn:
            try:
                self.conn.close()
            except:
                pass
            self.conn = None


# ============================================================================
# Setup Helper Functions
# ============================================================================

def setup_sql_tool(session, df_cleaned):
    """Setup or update SQL tool for chat (Single table - backward compatible)"""
    current_df_hash = hash(str(df_cleaned.values.tobytes()))
    
    need_recreate = False
    if 'sql_tool' not in st.session_state or st.session_state.sql_tool is None:
        need_recreate = True
    elif 'sql_tool_df_hash' not in st.session_state:
        need_recreate = True
    elif st.session_state.sql_tool_df_hash != current_df_hash:
        need_recreate = True
    
    if need_recreate:
        db_dir = Path("./agent_databases")
        db_dir.mkdir(exist_ok=True)
        db_path = db_dir / f"data_{session.session_id}.db"
        
        if 'sql_tool' in st.session_state and st.session_state.sql_tool:
            try:
                st.session_state.sql_tool.close()
            except:
                pass
        
        sql_tool = SQLQueryTool(str(db_path), df_cleaned)
        st.session_state.sql_tool = sql_tool
        st.session_state.sql_tool_df_hash = current_df_hash
        
        return sql_tool, True
    
    return st.session_state.sql_tool, False


def setup_multi_table_sql_tool(session, sources_dfs: Dict[str, pd.DataFrame], 
                                schemas: Dict[str, Dict] = None) -> MultiTableSQLQueryTool:
    """
    Setup ho·∫∑c c·∫≠p nh·∫≠t multi-table SQL tool.
    """
    combined_hash = hash(tuple(
        hash(str(df.values.tobytes())) 
        for df in sources_dfs.values()
    ))
    
    need_recreate = False
    if 'multi_sql_tool' not in st.session_state or st.session_state.multi_sql_tool is None:
        need_recreate = True
    elif 'multi_sql_tool_hash' not in st.session_state:
        need_recreate = True
    elif st.session_state.multi_sql_tool_hash != combined_hash:
        need_recreate = True
    
    if need_recreate:
        db_dir = Path("./agent_databases")
        db_dir.mkdir(exist_ok=True)
        db_path = db_dir / f"multi_data_{session.session_id}.db"
        
        if 'multi_sql_tool' in st.session_state and st.session_state.multi_sql_tool:
            try:
                st.session_state.multi_sql_tool.close()
            except:
                pass
        
        sql_tool = MultiTableSQLQueryTool(str(db_path))
        
        for source_id, df in sources_dfs.items():
            schema_info = {}
            if schemas and source_id in schemas:
                schema_info = {
                    col: {
                        "description": col_schema.description if hasattr(col_schema, 'description') else "",
                        "semantic_type": col_schema.semantic_type if hasattr(col_schema, 'semantic_type') else "",
                    }
                    for col, col_schema in schemas[source_id].items()
                }
            sql_tool.add_table(source_id, df, schema_info)
        
        st.session_state.multi_sql_tool = sql_tool
        st.session_state.multi_sql_tool_hash = combined_hash
        
        return sql_tool
    
    return st.session_state.multi_sql_tool


def get_all_available_dataframes(session) -> Dict[str, pd.DataFrame]:
    """L·∫•y t·∫•t c·∫£ c√°c DataFrame c√≥ s·∫µn t·ª´ session state."""
    sources_dfs = {}
    
    for source in session.sources:
        source_id = source.source_id
        df = st.session_state.cleaned_dfs.get(
            source_id,
            st.session_state.clean_dfs.get(
                source_id,
                st.session_state.raw_dfs.get(source_id)
            )
        )
        if df is not None:
            sources_dfs[source_id] = df
    
    return sources_dfs


# ============================================================================
# Chat State Management
# ============================================================================

def initialize_chat_state(context_key: str):
    chat_key = f"chat_history_{context_key}"
    if chat_key not in st.session_state:
        st.session_state[chat_key] = []


def get_chat_history(context_key: str) -> List[Dict[str, str]]:
    chat_key = f"chat_history_{context_key}"
    return st.session_state.get(chat_key, [])


def add_to_chat_history(context_key: str, role: str, content: str):
    chat_key = f"chat_history_{context_key}"
    if chat_key not in st.session_state:
        st.session_state[chat_key] = []
    
    st.session_state[chat_key].append({
        "role": role,
        "content": content,
        "timestamp": datetime.now().isoformat()
    })


def clear_chat_history(context_key: str):
    chat_key = f"chat_history_{context_key}"
    st.session_state[chat_key] = []


# ============================================================================
# Chat Interface Components
# ============================================================================

def render_chat_message(role: str, content: str, timestamp: str = None):
    if role == "user":
        st.markdown(f"""
        <div class="chat-message user-message">
            <strong>B·∫°n:</strong><br>{content}
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown(f"""
        <div class="chat-message assistant-message">
            <strong>Agent:</strong><br>{content}
        </div>
        """, unsafe_allow_html=True)


def stream_agent_response(agent, question: str, placeholder) -> Generator[str, None, None]:
    """
    Stream response t·ª´ agent (Single Table) d∆∞·ªõi d·∫°ng Generator.
    Gi√∫p UI hi·ªÉn th·ªã m∆∞·ª£t m√† t·ª´ng t·ª´.
    """
    full_response = ""
    try:
        for chunk in agent.query(question):
            if isinstance(chunk, dict):
                continue
            full_response += chunk
            placeholder.markdown(full_response + "‚ñå")
            yield chunk
        
        # K·∫øt th√∫c stream, hi·ªÉn th·ªã b·∫£n clean (b·ªè con tr·ªè)
        placeholder.markdown(full_response)
        
    except Exception as e:
        error_msg = f"‚ùå L·ªói: {str(e)}"
        placeholder.markdown(error_msg)
        yield error_msg


# ============================================================================
# Multi-Table Query with Streaming Support
# ============================================================================

def _build_multi_table_context(sql_tool: MultiTableSQLQueryTool, session) -> str:
    """Build context string for multi-table query"""
    context_parts = []
    
    context_parts.append("**üìä C√ÅC B·∫¢NG D·ªÆ LI·ªÜU:**")
    for table_name, info in sql_tool.tables.items():
        cols_preview = ', '.join(str(c) for c in info['columns'][:10])
        if len(info['columns']) > 10:
            cols_preview += f", ... (+{len(info['columns']) - 10} c·ªôt)"
        context_parts.append(f"- **{table_name}** ({info['row_count']} rows): {cols_preview}")
    
    if session.schema:
        context_parts.append("\n**üìã CHI TI·∫æT SCHEMA:**")
        for col_name, col_schema in list(session.schema.items()):
            if hasattr(col_schema, 'semantic_type') and hasattr(col_schema, 'description'):
                desc = col_schema.description[:60] if col_schema.description else ''
                context_parts.append(f"- {col_name}: {col_schema.semantic_type} - {desc}")
    
    if session.question_set and session.question_set.additional_notes:
        context_parts.append(f"\n**‚ö†Ô∏è QUY T·∫ÆC NGHI·ªÜP V·ª§:**\n{session.question_set.additional_notes[:500]}")
    
    if session.scenarios:
        context_parts.append("\n**üéØ SCENARIOS:**")
        for sc in session.scenarios:
            context_parts.append(f"- {sc.name}: {sc.description if sc.description else 'N/A'}")
    
    return "\n".join(context_parts)


def _stream_multi_table_query(question: str, sql_tool: MultiTableSQLQueryTool, 
                               session, placeholder) -> Generator[str, None, None]:
    """
    Query agent v·ªõi multi-table context V·ªöI STREAMING.
    H√†m n√†y yield t·ª´ng chunk text ƒë·ªÉ UI c·∫≠p nh·∫≠t.
    """
    from openai import OpenAI
    
    client = OpenAI(api_key=st.session_state.api_key)
    context = _build_multi_table_context(sql_tool, session)
    
    system_prompt = """B·∫°n l√† m·ªôt data analyst th√¥ng minh v·ªõi kh·∫£ nƒÉng query SQL tr√™n NHI·ªÄU B·∫¢NG.

**NGUY√äN T·∫ÆC:**
1. D√πng [table_name] cho t√™n b·∫£ng
2. D√πng table.column khi c·∫ßn ph√¢n bi·ªát
3. C√≥ th·ªÉ JOIN, UNION nhi·ªÅu b·∫£ng
4. LU√îN tr·∫£ l·ªùi b·∫±ng TI·∫æNG VI·ªÜT
5. N·∫øu c√≥ business rules ‚Üí tu√¢n theo

Khi c·∫ßn d·ªØ li·ªáu, d√πng tool execute_sql_query."""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"**Context:**\n{context}\n\n**C√¢u h·ªèi:**\n{question}"}
    ]
    
    tools = [{
        "type": "function",
        "function": {
            "name": "execute_sql_query",
            "description": f"Th·ª±c thi SQL SELECT query tr√™n c√°c b·∫£ng: {', '.join(sql_tool.tables.keys())}. D√πng [table_name] cho t√™n b·∫£ng.",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {"type": "string", "description": "SQL SELECT query"}
                },
                "required": ["query"]
            }
        }
    }]
    
    full_response = ""
    
    try:
        # B∆∞·ªõc 1: Agent suy nghƒ© v√† g·ªçi Tool (kh√¥ng stream ph·∫ßn n√†y, ch·ªâ hi·ªán status)
        placeholder.markdown("üîç Agent ƒëang ph√¢n t√≠ch...")
        
        response = client.chat.completions.create(
            model=st.session_state.get('model', 'gpt-4o-mini'),
            messages=messages,
            tools=tools,
            tool_choice="auto",
            temperature=0.7,
            max_tokens=2000
        )
        
        assistant_msg = response.choices[0].message
        
        # B∆∞·ªõc 2: X·ª≠ l√Ω Tool Call (SQL)
        if assistant_msg.tool_calls:
            sql_results = []
            
            for tool_call in assistant_msg.tool_calls:
                if tool_call.function.name == "execute_sql_query":
                    args = json.loads(tool_call.function.arguments)
                    query = args.get("query", "")
                    
                    placeholder.markdown(f"üîç ƒêang th·ª±c thi SQL:\n```sql\n{query}\n```")
                    
                    result_df, error = sql_tool.execute_query(query)
                    
                    if error:
                        sql_results.append(f"‚ùå SQL Error: {error}")
                    else:
                        if len(result_df) == 0:
                            sql_results.append("Query kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£")
                        else:
                            # Format k·∫øt qu·∫£ g·ªçn g√†ng
                            result_text = f"K·∫øt qu·∫£ ({len(result_df)} d√≤ng):\n```\n{result_df.head(15).to_string(index=False)}\n```"
                            if len(result_df) > 15:
                                result_text += f"\n(Hi·ªÉn th·ªã 15/{len(result_df)} d√≤ng)"
                            sql_results.append(result_text)
            
            result_summary = "\n\n".join(sql_results)
            
            # B∆∞·ªõc 3: Agent ph√¢n t√≠ch k·∫øt qu·∫£ cu·ªëi c√πng (STREAMING)
            placeholder.markdown("üìù ƒêang ph√¢n t√≠ch k·∫øt qu·∫£...")
            
            final_stream = client.chat.completions.create(
                model=st.session_state.get('model', 'gpt-4o-mini'),
                messages=[
                    {"role": "system", "content": "Ph√¢n t√≠ch k·∫øt qu·∫£ SQL v√† tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát. Tr·∫£ l·ªùi ng·∫Øn g·ªçn v√† r√µ r√†ng. Format markdown ƒë·∫πp."},
                    {"role": "user", "content": f"C√¢u h·ªèi: {question}\n\nK·∫øt qu·∫£ SQL:\n{result_summary}\n\nPh√¢n t√≠ch v√† tr·∫£ l·ªùi:"}
                ],
                temperature=0.7,
                max_tokens=1500,
                stream=True
            )
            
            for chunk in final_stream:
                if chunk.choices[0].delta.content:
                    text = chunk.choices[0].delta.content
                    full_response += text
                    # C·∫≠p nh·∫≠t UI ngay l·∫≠p t·ª©c
                    placeholder.markdown(full_response + "‚ñå")
                    # Yield text ƒë·ªÉ caller c√≥ th·ªÉ x·ª≠ l√Ω n·∫øu c·∫ßn
                    yield text

            placeholder.markdown(full_response)
            
        else:
            # Tr∆∞·ªùng h·ª£p kh√¥ng g·ªçi tool, tr·∫£ l·ªùi tr·ª±c ti·∫øp
            if assistant_msg.content:
                full_response = assistant_msg.content
                placeholder.markdown(full_response)
                yield full_response
            else:
                full_response = "Kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi t·ª´ Agent."
                placeholder.markdown(full_response)
                yield full_response
            
    except Exception as e:
        error_msg = f"‚ùå L·ªói: {str(e)}"
        placeholder.markdown(error_msg)
        yield error_msg

def _query_multi_table_for_chat(question: str, sql_tool: MultiTableSQLQueryTool, session) -> str:
    """Query agent v·ªõi multi-table context (KH√îNG STREAMING - backward compatible)"""
    from openai import OpenAI
    
    client = OpenAI(api_key=st.session_state.api_key)
    context = _build_multi_table_context(sql_tool, session)
    
    system_prompt = """B·∫°n l√† m·ªôt data analyst th√¥ng minh v·ªõi kh·∫£ nƒÉng query SQL tr√™n NHI·ªÄU B·∫¢NG.

**NGUY√äN T·∫ÆC:**
1. D√πng [table_name] cho t√™n b·∫£ng
2. D√πng table.column khi c·∫ßn ph√¢n bi·ªát
3. C√≥ th·ªÉ JOIN, UNION nhi·ªÅu b·∫£ng
4. LU√îN tr·∫£ l·ªùi b·∫±ng TI·∫æNG VI·ªÜT
5. N·∫øu c√≥ business rules ‚Üí tu√¢n theo

Khi c·∫ßn d·ªØ li·ªáu, d√πng tool execute_sql_query."""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"**Context:**\n{context}\n\n**C√¢u h·ªèi:**\n{question}"}
    ]
    
    tools = [{
        "type": "function",
        "function": {
            "name": "execute_sql_query",
            "description": f"Th·ª±c thi SQL SELECT query tr√™n c√°c b·∫£ng: {', '.join(sql_tool.tables.keys())}. D√πng [table_name] cho t√™n b·∫£ng.",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {"type": "string", "description": "SQL SELECT query"}
                },
                "required": ["query"]
            }
        }
    }]
    
    try:
        response = client.chat.completions.create(
            model=st.session_state.get('model', 'gpt-4o-mini'),
            messages=messages,
            tools=tools,
            tool_choice="auto",
            temperature=0.7,
            max_tokens=2000
        )
        
        assistant_msg = response.choices[0].message
        
        if assistant_msg.tool_calls:
            sql_results = []
            
            for tool_call in assistant_msg.tool_calls:
                if tool_call.function.name == "execute_sql_query":
                    args = json.loads(tool_call.function.arguments)
                    query = args.get("query", "")
                    
                    result_df, error = sql_tool.execute_query(query)
                    
                    if error:
                        sql_results.append(f"‚ùå SQL Error: {error}")
                    else:
                        if len(result_df) == 0:
                            sql_results.append("Query kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£")
                        else:
                            result_text = f"K·∫øt qu·∫£ ({len(result_df)} d√≤ng):\n```\n{result_df.head(15).to_string(index=False)}\n```"
                            if len(result_df) > 15:
                                result_text += f"\n(Hi·ªÉn th·ªã 15/{len(result_df)} d√≤ng)"
                            sql_results.append(result_text)
            
            result_summary = "\n\n".join(sql_results)
            
            final_response = client.chat.completions.create(
                model=st.session_state.get('model', 'gpt-4o-mini'),
                messages=[
                    {"role": "system", "content": "Ph√¢n t√≠ch k·∫øt qu·∫£ SQL v√† tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát."},
                    {"role": "user", "content": f"C√¢u h·ªèi: {question}\n\nK·∫øt qu·∫£ SQL:\n{result_summary}\n\nPh√¢n t√≠ch v√† tr·∫£ l·ªùi:"}
                ],
                temperature=0.7,
                max_tokens=1500
            )
            
            return final_response.choices[0].message.content
        else:
            return assistant_msg.content or "Kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi"
            
    except Exception as e:
        return f"‚ùå L·ªói: {str(e)}"



def render_chat_interface(
    session,
    agent,
    context_key: str,
    placeholder_text: str = "H·ªèi m·ªôt c√¢u ƒë·ªÉ test...",
    quick_questions: List[str] = None
):
    """Render chat interface for validation with STREAMING support (Generator Safe)"""
    initialize_chat_state(context_key)
    
    chat_history = get_chat_history(context_key)
    
    # Hi·ªÉn th·ªã l·ªãch s·ª≠
    if not chat_history:
        st.info("üí¨ B·∫Øt ƒë·∫ßu chat ƒë·ªÉ test c√¢u h·ªèi c·ªßa b·∫°n! Agent s·∫Ω tr·∫£ l·ªùi d·ª±a tr√™n d·ªØ li·ªáu th·ª±c.")
    else:
        chat_container = st.container()
        with chat_container:
            for msg in chat_history:
                # Safety check khi render
                content = msg["content"]
                if not isinstance(content, str):
                    content = str(content)
                render_chat_message(msg["role"], content, msg.get("timestamp"))
    
    # X·ª≠ l√Ω Quick Questions
    if quick_questions:
        st.markdown("**üí° C√¢u h·ªèi g·ª£i √Ω:**")
        cols = st.columns(min(len(quick_questions), 3))
        for i, q in enumerate(quick_questions[:6]):
            with cols[i % 3]:
                btn_label = q[:30] + "..." if len(q) > 30 else q
                if st.button(f"üí¨ {btn_label}", key=f"{context_key}_quick_{i}"):
                    # 1. Add User Question
                    add_to_chat_history(context_key, "user", q)
                    render_chat_message("user", q)
                    # 2. Stream & Accumulate
                    response_placeholder = st.empty()
                    gen = stream_agent_response(agent, q, response_placeholder)
                    
                    full_response = ""
                    logger.info(f"GENERATOR 1: {gen}")
                    for chunk in gen:
                        full_response += chunk
                        logger.info(f"CHUNK 1: {chunk}")
                    # 3. Save String Only
                    add_to_chat_history(context_key, "assistant", full_response)
                    logger.info(f"FULL RESPONSE 1: {full_response}")

                    st.rerun()
    
    st.markdown("---")
    with st.form(f"chat_form_{context_key}", clear_on_submit=True):
        user_input = st.text_input(
            "Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n:",
            placeholder=placeholder_text,
            key=f"chat_input_{context_key}"
        )
        
        col1, col2, col3 = st.columns([1, 1, 4])
        with col1:
            submitted = st.form_submit_button("üì§ G·ª≠i", type="primary")
        with col2:
            clear = st.form_submit_button("üóëÔ∏è X√≥a chat")
    
    if clear:
        clear_chat_history(context_key)
        st.rerun()
    
    if submitted and user_input:
        add_to_chat_history(context_key, "user", user_input)
        render_chat_message("user", user_input)
        response_placeholder = st.empty()
        
        # FIX: Loop generator to get full string
        gen = stream_agent_response(agent, user_input, response_placeholder)
        full_response = ""
        logger.info(f"GENERATOR 2: {gen}")

        for chunk in gen:
            full_response += chunk
            logger.info(f"CHUNK 2: {chunk}")
        add_to_chat_history(context_key, "assistant", full_response)
        logger.info(f"FULL RESPONSE 3: {full_response}")
        st.rerun()


def render_multi_table_chat_interface(
    session,
    sql_tool,
    context_key: str,
    placeholder_text: str = "H·ªèi v·ªÅ d·ªØ li·ªáu trong c√°c b·∫£ng...",
    quick_questions: List[str] = None
):
    """Render chat interface v·ªõi h·ªó tr·ª£ nhi·ªÅu b·∫£ng V√Ä STREAMING (Generator Safe)"""
    initialize_chat_state(context_key)
    
    tables_info = sql_tool.get_tables_info()
    with st.expander(f"üìä C√°c b·∫£ng c√≥ s·∫µn ({tables_info['total_tables']} b·∫£ng)", expanded=False):
        for table in tables_info["tables"]:
            cols_preview = ', '.join(str(c) for c in table['columns'][:6])
            if len(table['columns']) > 6:
                cols_preview += f" ... (+{len(table['columns']) - 6} c·ªôt)"
            st.markdown(f"‚Ä¢ **{table['name']}** ({table['row_count']} rows): {cols_preview}")
    
    chat_history = get_chat_history(context_key)
    
    if not chat_history:
        st.info("üí¨ B·∫Øt ƒë·∫ßu chat ƒë·ªÉ test c√¢u h·ªèi! Agent c√≥ th·ªÉ query tr√™n nhi·ªÅu b·∫£ng.")
    else:
        chat_container = st.container()
        with chat_container:
            for msg in chat_history:
                # Safety check
                content = msg["content"]
                if not isinstance(content, str):
                    content = str(content)
                render_chat_message(msg["role"], content, msg.get("timestamp"))
    
    # X·ª≠ l√Ω Quick Questions
    if quick_questions:
        st.markdown("**üí° C√¢u h·ªèi g·ª£i √Ω:**")
        cols = st.columns(min(len(quick_questions), 3))
        for i, q in enumerate(quick_questions[:6]):
            with cols[i % 3]:
                btn_label = q[:30] + "..." if len(q) > 30 else q
                if st.button(f"üí¨ {btn_label}", key=f"{context_key}_quick_{i}"):
                    # 1. Add User Question
                    add_to_chat_history(context_key, "user", q)
                    render_chat_message("user", q)
                    
                    # 2. Stream & Accumulate
                    response_placeholder = st.empty()
                    gen = _stream_multi_table_query(q, sql_tool, session, response_placeholder)
                    
                    full_response = ""
                    for chunk in gen:
                        full_response += chunk
                    
                    # 3. Save String Only
                    add_to_chat_history(context_key, "assistant", full_response)
                    logger.info(f"FULL RESPONSE 4: {full_response}")
                    st.rerun()
    
    st.markdown("---")
    with st.form(f"chat_form_{context_key}", clear_on_submit=True):
        user_input = st.text_input(
            "Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n:",
            placeholder=placeholder_text,
            key=f"chat_input_{context_key}"
        )
        
        col1, col2, col3 = st.columns([1, 1, 4])
        with col1:
            submitted = st.form_submit_button("üì§ G·ª≠i", type="primary")
        with col2:
            clear = st.form_submit_button("üóëÔ∏è X√≥a chat")
    
    if clear:
        clear_chat_history(context_key)
        st.rerun()
    
    if submitted and user_input:
        add_to_chat_history(context_key, "user", user_input)
        render_chat_message("user", user_input)
        
        response_placeholder = st.empty()
        
        # FIX: Loop generator to get full string
        gen = _stream_multi_table_query(user_input, sql_tool, session, response_placeholder)
        full_response = ""
        for chunk in gen:
            full_response += chunk
            
        add_to_chat_history(context_key, "assistant", full_response)
        logger.info(f"FULL RESPONSE 5: {full_response}")
        st.rerun()

# ============================================================================
# Add Chat Validation Functions
# ============================================================================

def add_chat_validation_to_questions_tab(session, df_cleaned, sql_tool, 
                                          use_multi_table: bool = False,
                                          sources_dfs: Dict[str, pd.DataFrame] = None):
    """Add interactive chat validation to Questions tab"""
    st.divider()
    st.subheader("üîç Test C√¢u h·ªèi v·ªõi Agent")
    
    if not session.question_set or not session.question_set.user_questions:
        st.info("üìù T·∫°o c√¢u h·ªèi ·ªü ph·∫ßn tr√™n, sau ƒë√≥ quay l·∫°i ƒë√¢y ƒë·ªÉ test!")
        return
    
    user_questions = [q.question for q in session.question_set.user_questions]
    
    # --- MULTI TABLE MODE ---
    if use_multi_table and sources_dfs and len(sources_dfs) > 1:
        st.info(f"üìä **Ch·∫ø ƒë·ªô Multi-Table**: Query tr√™n {len(sources_dfs)} b·∫£ng")
        
        multi_sql_tool = setup_multi_table_sql_tool(session, sources_dfs, 
                                                     {sid: session.schema for sid in sources_dfs})
        
        col1, col2 = st.columns([3, 1])
        with col1:
            st.success(f"üí° B·∫°n ƒë√£ t·∫°o **{len(user_questions)}** c√¢u h·ªèi. Test v·ªõi **{len(sources_dfs)} b·∫£ng**!")
        with col2:
            if st.button("üìã Copy c√¢u h·ªèi", key="copy_questions_mt"):
                questions_text = "\n".join([f"{i+1}. {q}" for i, q in enumerate(user_questions)])
                st.code(questions_text)
        
        render_multi_table_chat_interface(
            session=session,
            sql_tool=multi_sql_tool,
            context_key="questions_validation_multi",
            placeholder_text="V√≠ d·ª•: So s√°nh d·ªØ li·ªáu gi·ªØa c√°c b·∫£ng, JOIN b·∫£ng A v√† B...",
            quick_questions=user_questions
        )
        
    # --- SINGLE TABLE MODE ---
    else:
        if 'validation_agent' not in st.session_state or st.session_state.validation_agent is None:
            from hst_agent import DataSchemaAgent
            agent = DataSchemaAgent(
                session,
                st.session_state.api_key,
                st.session_state.model,
                df_cleaned=df_cleaned,
                sql_tool=sql_tool
            )
            st.session_state.validation_agent = agent
        else:
            agent = st.session_state.validation_agent
            if sql_tool and agent.sql_tool != sql_tool:
                agent.sql_tool = sql_tool
                agent.db_path = sql_tool.db_path
                agent.df_cleaned = df_cleaned
        
        agent = st.session_state.validation_agent
        
        col1, col2 = st.columns([3, 1])
        with col1:
            st.info(f"üí° B·∫°n ƒë√£ t·∫°o **{len(user_questions)}** c√¢u h·ªèi. Test v·ªõi agent!")
        with col2:
            if st.button("üìã Copy c√¢u h·ªèi", key="copy_questions"):
                questions_text = "\n".join([f"{i+1}. {q}" for i, q in enumerate(user_questions)])
                st.code(questions_text)
        
        render_chat_interface(
            session=session,
            agent=agent,
            context_key="questions_validation",
            placeholder_text="V√≠ d·ª•: What is the average price?",
            quick_questions=user_questions
        )


def add_chat_validation_to_scenarios_tab(session, df_cleaned, sql_tool,
                                          use_multi_table: bool = False,
                                          sources_dfs: Dict[str, pd.DataFrame] = None):
    """Add interactive chat validation to Scenarios tab V·ªöI STREAMING"""
    st.divider()
    st.subheader("üîç Test Scenario v·ªõi Agent")
    
    if not session.scenarios:
        st.info("üìù T·∫°o scenario ·ªü ph·∫ßn tr√™n, sau ƒë√≥ quay l·∫°i ƒë√¢y ƒë·ªÉ test!")
        return
    
    scenario_names = [s.name for s in session.scenarios]
    selected_scenario_name = st.selectbox(
        "Ch·ªçn scenario ƒë·ªÉ test:",
        options=scenario_names,
        key="test_scenario_select"
    )
    
    selected_scenario = next(
        (s for s in session.scenarios if s.name == selected_scenario_name),
        None
    )
    
    if not selected_scenario:
        return
    
    with st.expander("‚ÑπÔ∏è Th√¥ng tin Scenario", expanded=False):
        st.write(f"**T√™n:** {selected_scenario.name}")
        st.write(f"**M√¥ t·∫£:** {selected_scenario.description or 'N/A'}")
        st.write(f"**Selected Fields:** `{', '.join(selected_scenario.selected_fields)}`")
        st.write(f"**S·ªë c√¢u h·ªèi:** {len(selected_scenario.questions)}")
    
    is_multi = use_multi_table and sources_dfs and len(sources_dfs) > 1
    context_key = f"scenario_{selected_scenario.id}_multi" if is_multi else f"scenario_{selected_scenario.id}"
    
    # --- MULTI TABLE SCENARIO ---
    if is_multi:
        st.info(f"üìä **Ch·∫ø ƒë·ªô Multi-Table**: Query tr√™n {len(sources_dfs)} b·∫£ng")
        
        multi_sql_tool = setup_multi_table_sql_tool(session, sources_dfs,
                                                     {sid: session.schema for sid in sources_dfs})
        
        render_multi_table_chat_interface(
            session=session,
            sql_tool=multi_sql_tool,
            context_key=context_key,
            placeholder_text="H·ªèi v·ªÅ scenario ho·∫∑c query tr√™n nhi·ªÅu b·∫£ng...",
            quick_questions=selected_scenario.questions
        )
        
        # === FIX: TEST ALL QUESTIONS (Multi-Table) ===
        st.divider()
        st.markdown("### üß™ Test T·ª± ƒê·ªông (Streaming)")
        
        if st.button("‚ñ∂Ô∏è Test All Questions", type="primary", key="auto_test_scenario_multi"):
            clear_chat_history(context_key)
            
            for i, question in enumerate(selected_scenario.questions):
                st.markdown(f"---\n**[Q{i+1}] {question}**")
                add_to_chat_history(context_key, "user", f"[Q{i+1}] {question}")
                
                response_placeholder = st.empty()
                
                # G·ªçi generator
                gen = _stream_multi_table_query(question, multi_sql_tool, session, response_placeholder)
                
                # Gom to√†n b·ªô text t·ª´ generator
                full_response = ""
                for chunk in gen:
                    full_response += chunk
                
                # L∆∞u text ƒë·∫ßy ƒë·ªß v√†o history (KH√îNG l∆∞u generator object)
                add_to_chat_history(context_key, "assistant", full_response)
            
            st.success(f"‚úÖ ƒê√£ test {len(selected_scenario.questions)} c√¢u h·ªèi!")
            # Kh√¥ng rerun ·ªü ƒë√¢y ƒë·ªÉ ng∆∞·ªùi d√πng th·∫•y k·∫øt qu·∫£ streaming cu·ªëi c√πng
            # N·∫øu rerun, history s·∫Ω hi·ªÉn th·ªã ƒë√∫ng text ƒë·∫ßy ƒë·ªß

    # --- SINGLE TABLE SCENARIO ---
    else:
        if 'validation_agent' not in st.session_state or st.session_state.validation_agent is None:
            from hst_agent import DataSchemaAgent
            agent = DataSchemaAgent(
                session,
                st.session_state.api_key,
                st.session_state.model,
                df_cleaned=df_cleaned,
                sql_tool=sql_tool
            )
            st.session_state.validation_agent = agent
        else:
            agent = st.session_state.validation_agent
            if sql_tool and agent.sql_tool != sql_tool:
                agent.sql_tool = sql_tool
                agent.db_path = sql_tool.db_path
                agent.df_cleaned = df_cleaned
        
        agent = st.session_state.validation_agent
        
        render_chat_interface(
            session=session,
            agent=agent,
            context_key=context_key,
            placeholder_text="H·ªèi m·ªôt c√¢u t·ª´ scenario ho·∫∑c c√¢u h·ªèi m·ªõi...",
            quick_questions=selected_scenario.questions
        )
        
        # === FIX: TEST ALL QUESTIONS (Single Table) ===
        st.divider()
        st.markdown("### üß™ Test T·ª± ƒê·ªông (Streaming)")
        
        if st.button("‚ñ∂Ô∏è Test All Questions", type="primary", key="auto_test_scenario"):
            clear_chat_history(context_key)
            
            for i, question in enumerate(selected_scenario.questions):
                st.markdown(f"---\n**[Q{i+1}] {question}**")
                add_to_chat_history(context_key, "user", f"[Q{i+1}] {question}")
                
                response_placeholder = st.empty()
                
                # G·ªçi generator
                gen = stream_agent_response(agent, question, response_placeholder)
                
                # Gom to√†n b·ªô text
                full_response = ""
                for chunk in gen:
                    full_response += chunk
                
                # L∆∞u text ƒë·∫ßy ƒë·ªß v√†o history
                add_to_chat_history(context_key, "assistant", full_response)
            
            st.success(f"‚úÖ ƒê√£ test {len(selected_scenario.questions)} c√¢u h·ªèi!")

# ============================================================================
# Export chat history
# ============================================================================

# ============================================================================
# FIXED: Export chat history (Safety Version)
# ============================================================================

def export_chat_history_to_json(context_key: str, filename: str = None):
    """Export chat history to JSON file with safety checks for generators"""
    chat_history = get_chat_history(context_key)
    
    if not chat_history:
        return None
    
    if filename is None:
        filename = f"chat_history_{context_key}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    
    # Sanitize history: Convert generators or non-serializable objects to string
    safe_history = []
    for msg in chat_history:
        safe_msg = msg.copy()
        content = safe_msg.get("content")
        
        # Ki·ªÉm tra n·∫øu content kh√¥ng ph·∫£i string (v√≠ d·ª• l√† generator), convert sang string
        if not isinstance(content, str):
            if content is None:
                safe_msg["content"] = ""
            else:
                # N·∫øu l√† generator, ta kh√¥ng c·ª©u ƒë∆∞·ª£c n·ªôi dung ƒë√£ m·∫•t, nh∆∞ng tr√°nh ƒë∆∞·ª£c crash
                safe_msg["content"] = str(content) 
        
        safe_history.append(safe_msg)
    
    export_data = {
        "context": context_key,
        "exported_at": datetime.now().isoformat(),
        "message_count": len(safe_history),
        "messages": safe_history
    }
    
    # D√πng default=str ƒë·ªÉ force convert m·ªçi th·ª© c√≤n s√≥t l·∫°i th√†nh string
    json_str = json.dumps(export_data, indent=2, ensure_ascii=False, default=str)
    return json_str

def render_export_chat_button(context_key: str):
    """Render button to export chat history"""
    chat_history = get_chat_history(context_key)
    
    if chat_history:
        json_str = export_chat_history_to_json(context_key)
        if json_str:
            st.download_button(
                label="‚¨áÔ∏è Export Chat History",
                data=json_str,
                file_name=f"chat_{context_key}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                key=f"export_chat_{context_key}"
            )


# ============================================================================
# Statistics and Analysis
# ============================================================================

def get_chat_statistics(context_key: str) -> Dict[str, Any]:
    """Get statistics about chat history (Safe version)"""
    chat_history = get_chat_history(context_key)
    
    if not chat_history:
        return {
            "total_messages": 0,
            "user_messages": 0,
            "agent_messages": 0,
            "avg_response_length": 0
        }
    
    user_msgs = [msg for msg in chat_history if msg["role"] == "user"]
    agent_msgs = [msg for msg in chat_history if msg["role"] == "assistant"]
    
    # T√≠nh t·ªïng ƒë·ªô d√†i an to√†n (ki·ªÉm tra xem content c√≥ ph·∫£i string kh√¥ng)
    total_length = 0
    for msg in agent_msgs:
        content = msg.get("content", "")
        if isinstance(content, str):
            total_length += len(content)
        # N·∫øu l√† generator ho·∫∑c object kh√°c, ta b·ªè qua ho·∫∑c t√≠nh l√† 0 ƒë·ªÉ kh√¥ng g√¢y l·ªói
    
    avg_length = total_length / len(agent_msgs) if agent_msgs else 0
    
    return {
        "total_messages": len(chat_history),
        "user_messages": len(user_msgs),
        "agent_messages": len(agent_msgs),
        "avg_response_length": avg_length
    }

def render_chat_statistics(context_key: str):
    """Render chat statistics"""
    stats = get_chat_statistics(context_key)
    
    if stats["total_messages"] > 0:
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("T·ªïng tin nh·∫Øn", stats["total_messages"])
        with col2:
            st.metric("C√¢u h·ªèi", stats["user_messages"])
        with col3:
            st.metric("C√¢u tr·∫£ l·ªùi", stats["agent_messages"])
        with col4:
            st.metric("ƒê·ªô d√†i TB", f"{stats['avg_response_length']:.0f} chars")
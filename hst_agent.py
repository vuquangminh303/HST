# hst_agent.py - HST Agent with Text2SQL and ReAct mechanism
"""HST Agent for querying tender records database using Text2SQL with ReAct strategy"""
import logging
import os
import time
import redis
import json
import hashlib
import asyncio
from decimal import Decimal
from typing import List, Dict, Any, Generator, Optional, Tuple, AsyncGenerator
from sqlalchemy import create_engine, text, inspect
from sqlalchemy.exc import SQLAlchemyError, OperationalError, TimeoutError as SQLTimeoutError
from openai import OpenAI, AsyncOpenAI, RateLimitError, APIConnectionError, AuthenticationError
from src.common import TokenUsage
from src.utils.utils_logging import log_openai_agent_response, log_openai_agent_error
from datetime import datetime
import re

logger = logging.getLogger(__name__)

# ERROR CODE MAPPING
ERROR_CODES = {
    "rate_limit": "01",
    "authentication": "02",
    "not_found": "03",
    "connection": "04",
    "timeout": "05",
    "sql_error": "06",
    "general": "99"
}


# ============================================================================
# SCHEMA METADATA - Ng·ªØ nghƒ©a cho t·ª´ng c·ªôt
# ============================================================================
SCHEMA_METADATA = {
    "NƒÉm_ph√™_duy·ªát_KQLCNT": {
        "description": "NƒÉm ph√™ duy·ªát k·∫øt qu·∫£ l·ª±a ch·ªçn nh√† th·∫ßu (YYYY)",
        "type": "bigint",
        "unique values": "2024, 2025"
    },
    "Th·ªùi_gian_ph√™_duy·ªát_KQLCNT": {
        "description": "Th√°ng ph√™ duy·ªát k·∫øt qu·∫£ l·ª±a ch·ªçn nh√† th·∫ßu",
        "type": "text",
        "unique values": "Th√°ng 01, th√°ng 02, ..., Th√°ng 12",
    },
    "S·ªë_th√¥ng_b√°o_m·ªùi_th·∫ßu": {
        "description": "M√£ s·ªë th√¥ng b√°o m·ªùi th·∫ßu",
        "type": "text",
        "example": "IB2400101502-00"
    },
    "T√™n_b√™n_tr√∫ng_th·∫ßu": {
        "description": "T√™n c√¥ng ty tr√∫ng th·∫ßu",
        "type": "text",
        "example": "C√îNG TY TNHH FPT IS, C√îNG TY TNHH H·ªÜ TH·ªêNG TH√îNG TIN FPT"
    },
    "T√™n_b√™n_m·ªùi_th·∫ßu": {
        "description": "T√™n kh√°ch h√†ng/b√™n m·ªùi th·∫ßu",
        "type": "text",
        "example": "NG√ÇN H√ÄNG TH∆Ø∆†NG M·∫†I C·ªî PH·∫¶N ƒê·∫¶U T∆Ø V√Ä PH√ÅT TRI·ªÇN VI·ªÜT NAM"
    },
    "T√™n_g√≥i_th·∫ßu": {
        "description": "T√™n g√≥i th·∫ßu/d·ª± √°n",
        "type": "text",
        "example": "Mua s·∫Øm trang thi·∫øt b·ªã ph·ª•c v·ª• c√¥ng t√°c l√Ω l·ªãch t∆∞ ph√°p"
    },
    "Gi√°_tr√∫ng_th·∫ßu": {
        "description": "Gi√° tr·ªã tr√∫ng th·∫ßu (t·ª∑ VND)",
        "type": "double precision",
        "example": "0.2818005, 1.9646627",
        "note": "D√πng c·ªôt n√†y ƒë·ªÉ t√≠nh to√°n, s·∫Øp x·∫øp, t·ªïng h·ª£p"
    },
    "H√¨nh_th·ª©c_LCNT": {
        "description": "H√¨nh th·ª©c l·ª±a ch·ªçn nh√† th·∫ßu",
        "type": "text",
        "example": "Tham gia th·ª±c hi·ªán c·ªông ƒë·ªìng, ƒê√†m ph√°n gi√°, Ch·ªâ ƒë·ªãnh th·∫ßu r√∫t g·ªçn"
    },
    "M√£_t·ªânh_c≈©": {
        "description": "M√£ t·ªânh c≈© c·ªßa kh√°ch h√†ng",
        "type": "text",
        "example": "HNI, QBH"
    },
    "M√£_t·ªânh_m·ªõi": {
        "description": "M√£ t·ªânh m·ªõi c·ªßa kh√°ch h√†ng",
        "type": "text",
        "example": "HNI, HUE"
    },
    "Lƒ©nh_v·ª±c_Kh√°ch_h√†ng": {
        "description": "Lƒ©nh v·ª±c c·ªßa kh√°ch h√†ng",
        "type": "text",
        "unique values": "GDS, BQP, TW, CQT, YTS, KHDN",
        "values": {
            "GDS": "Gi√°o d·ª•c s·ªë",
            "BQP": "B·ªô qu·ªëc ph√≤ng",
            "TW": "Trung ∆∞∆°ng/B·ªô ng√†nh",
            "CQT": "Ch√≠nh quy·ªÅn t·ªânh",
            "YTS": "Y t·∫ø s·ªë",
            "KHDN": "Kh√°ch h√†ng doanh nghi·ªáp",
        }
    },
    "ƒê∆°n_v·ªã_kinh_doanh(VTS)": {
        "description": "ƒê∆°n v·ªã kinh doanh c·ªßa VTS",
        "type": "text",
        "unique values": "TT CQƒêT, P KHHN, TT GPYTS, TT DTTM, TT GPGDS, TT KHDN, TT QPAN, TT GPMN",
        "values": {
            "TT CQƒêT": "Trung t√¢m Ch√≠nh quy·ªÅn ƒëi·ªán t·ª≠",
            "TT GPYTS": "Trung t√¢m Gi·∫£i ph√°p Y t·∫ø s·ªë",
            "TT DTTM": "Trung t√¢m ƒê√¥ th·ªã th√¥ng minh",
            "TT GPGDS": "Trung t√¢m Gi·∫£i ph√°p Gi√°o d·ª•c s·ªë",
            "TT KHDN": "Trung t√¢m Kh√°ch h√†ng doanh nghi·ªáp",
            "TT QPAN": "Trung t√¢m Qu·ªëc ph√≤ng an ninh",
            "TT GPMN": "Trung t√¢m Gi·∫£i ph√°p mi·ªÅn Nam"
        }
    },
    "Ph√¢n_lo·∫°i_s·∫£n_ph·∫©m": {
        "description": "Lo·∫°i s·∫£n ph·∫©m/d·ªãch v·ª•",
        "type": "text",
        "unique values": "Ph·∫ßn m·ªÅm, K√™nh truy·ªÅn, d·ªãch v·ª•, ph·∫ßn c·ª©ng, [null]"
    },
    "Nh√≥m_m·ªùi_th·∫ßu": {
        "description": "Nh√≥m ph√¢n lo·∫°i b√™n m·ªùi th·∫ßu",
        "type": "text",
        "unique values": "d·ªãch v·ª• ƒë·∫∑c th√π, Kh√°c, X1"
    },
    "Nh√≥m_tr√∫ng_th·∫ßu": {
        "description": "T√™n c√¥ng ty tr√∫ng th·∫ßu",
        "type": "text",
        "example": "FPT, Viettel-IDC, Viettel-VCC, VNPT, Viettel-Kh√°c",
        "note": "C√°c gi√° tr·ªã li√™n quan Viettel c·∫ßn l·ªçc b·∫±ng ILIKE '%Viettel%', kh√¥ng d√πng = 'VTS'"
    },
    "Nh√≥m_tr√∫ng_th·∫ßu_shortlist": {
        "description": "T√™n c√¥ng ty tr√∫ng th·∫ßu, group th√†nh 4 nh√≥m ch√≠nh.",
        "type": "text",
        "unique values": "FPT, Viettel, VNPT, kh√°c"
    },
    "NƒÉm_ph√°t_h√†nh_TBMT": {
        "description": "NƒÉm ph√°t h√†nh th√¥ng b√°o m·ªùi th·∫ßu",
        "type": "text",
        "unique values": "2022, 2023, 2024, 2025"
    },
    "Thoi_gian_phe_duyet": {
        "description": "Th·ªùi gian ph√™ duy·ªát (datetime format)",
        "type": "datetime",
        "pg_type": "timestamp without time zone",
        "validation": "datetime",
        "example": "2024-10-01 00:00:00",
        "note": "D√πng ƒë·ªÉ filter theo th√°ng/nƒÉm ch√≠nh x√°c"
    }
}


###############################################################################
# UNIFIED GUIDE
###############################################################################

GENERAL_GUIDE_COMBINED = """
C√ÅC T√åNH HU·ªêNG M·∫™U (Intent Examples) D√ÄNH CHO TR·ª¢ L√ù H·ªí S∆† TH·∫¶U (HST)

1. **Ph√¢n t√≠ch th·ªã ph·∫ßn (market_share)**
- H·ªèi: "Th·ªã ph·∫ßn c·ªßa Viettel so v·ªõi FPT trong th√°ng 10/2025 l√† bao nhi√™u?"
- H∆∞·ªõng d·∫´n: d√πng WHERE "Nh√≥m_tr√∫ng_th·∫ßu" ILIKE '%Viettel%' GROUP BY "Nh√≥m_tr√∫ng_th·∫ßu",
  SUM("Gi√°_tr√∫ng_th·∫ßu"), t√≠nh t·ªïng v√† %.

2. **Ph√¢n t√≠ch ƒë·ªëi th·ªß (competitor_analysis)**
- H·ªèi: "So s√°nh k·∫øt qu·∫£ ƒë·∫•u th·∫ßu gi·ªØa Viettel, VNPT v√† FPT"
- H∆∞·ªõng d·∫´n: nh√≥m theo "Nh√≥m_tr√∫ng_th·∫ßu_shortlist", t√≠nh t·ªïng gi√° tr·ªã v√† ƒë·∫øm s·ªë g√≥i.

3. **Ph√¢n t√≠ch theo th·ªùi gian (time_series)**
- H·ªèi: "Xu h∆∞·ªõng gi√° tr·ªã tr√∫ng th·∫ßu qua c√°c th√°ng nƒÉm 2025"
- H∆∞·ªõng d·∫´n: GROUP BY "NƒÉm_ph√™_duy·ªát_KQLCNT", "Th·ªùi_gian_ph√™_duy·ªát_KQLCNT", SUM("Gi√°_tr√∫ng_th·∫ßu").

4. **Ph√¢n t√≠ch theo ƒë∆°n v·ªã (unit_performance)**
- H·ªèi: "Trung t√¢m n√†o c·ªßa Viettel c√≥ gi√° tr·ªã tr√∫ng th·∫ßu cao nh·∫•t?"
- H∆∞·ªõng d·∫´n: GROUP BY "ƒê∆°n_v·ªã_kinh_doanh(VTS)", SUM("Gi√°_tr√∫ng_th·∫ßu").

5. **Ph√¢n t√≠ch NSNN (nsnn_analysis)**
- H·ªèi: "Th·ªã ph·∫ßn Viettel trong lƒ©nh v·ª±c NSNN 10 th√°ng ƒë·∫ßu nƒÉm 2025"
- H∆∞·ªõng d·∫´n: WHERE "Lƒ©nh_v·ª±c_Kh√°ch_h√†ng" IN ('YTS','GDS','CQT'),
  d√πng "Thoi_gian_phe_duyet" ƒë·ªÉ l·ªçc th·ªùi gian, t√≠nh t·ªïng th·ªã tr∆∞·ªùng v√† Viettel.

6. **Top h·ª£p ƒë·ªìng (top_contracts)**
- H·ªèi: "Top 5 g√≥i th·∫ßu c√≥ gi√° tr·ªã cao nh·∫•t trong th√°ng 9"
- H∆∞·ªõng d·∫´n: ORDER BY "Gi√°_tr√∫ng_th·∫ßu" DESC LIMIT 5.

7. **B√°o c√°o t·ªïng quan th·ªã tr∆∞·ªùng (market_overview)**
- H·ªèi: "B√°o c√°o t·ªïng quan th·ªã tr∆∞·ªùng th·∫ßu l≈©y k·∫ø 10 th√°ng" ho·∫∑c 
       "T·ªïng quan th·ªã tr∆∞·ªùng ƒë·∫•u th·∫ßu nƒÉm 2025 ƒë·∫øn nay"
- G·ª£i √Ω SQL:
  ```sql
  SELECT 
      "Nh√≥m_tr√∫ng_th·∫ßu_shortlist",
      COUNT(*) AS tong_so_goi,
      SUM("Gi√°_tr√∫ng_th·∫ßu") AS tong_gia_tri_thi_truong
  FROM thau_2025
  WHERE "Thoi_gian_phe_duyet" >= DATE_TRUNC('year', CURRENT_DATE)
      AND "Thoi_gian_phe_duyet" < DATE_TRUNC('month', CURRENT_DATE)
  GROUP BY "Nh√≥m_tr√∫ng_th·∫ßu_shortlist"
  ORDER BY tong_gia_tri_thi_truong DESC;
  ```
- G·ª£i √Ω hi·ªÉn th·ªã: b·∫£ng t·ªïng h·ª£p th·ªã ph·∫ßn t·ª´ng nh√≥m (FPT, Viettel, VNPT, Kh√°c) k√®m s·ªë l∆∞·ª£ng g√≥i v√† t·ªïng gi√° tr·ªã.

8. **B√°o c√°o th·ªã ph·∫ßn th√°ng c·ª• th·ªÉ (monthly_market_share_report)**
- H·ªèi: "B√°o c√°o th·ªã ph·∫ßn th·∫ßu th√°ng 10/2025"
- H∆∞·ªõng d·∫´n: T·ªïng h·ª£p gi√° tr·ªã tr√∫ng th·∫ßu theo "Nh√≥m_tr√∫ng_th·∫ßu", l·ªçc theo th√°ng 10 v√† nƒÉm 2025.
- G·ª£i √Ω SQL:
  ```sql
    SELECT 
        "Nh√≥m_tr√∫ng_th·∫ßu",
        SUM("Gi√°_tr√∫ng_th·∫ßu") AS tong_gia_tri_trung_thau,
        COUNT(*) AS so_goi_thau,
        ROUND(
            CAST(SUM("Gi√°_tr√∫ng_th·∫ßu") * 100.0 /
            SUM(SUM("Gi√°_tr√∫ng_th·∫ßu")) OVER () AS numeric), 
            2
        ) AS thi_phan_phan_tram
    FROM thau_2025
    WHERE 
        "NƒÉm_ph√™_duy·ªát_KQLCNT" = 2025
        AND LOWER("Th·ªùi_gian_ph√™_duy·ªát_KQLCNT") IN ('th√°ng 10')
        AND "Gi√°_tr√∫ng_th·∫ßu" IS NOT NULL
        AND "Gi√°_tr√∫ng_th·∫ßu" > 0
        AND "Nh√≥m_tr√∫ng_th·∫ßu" != 'Kh√°c'
    GROUP BY "Nh√≥m_tr√∫ng_th·∫ßu"
    ORDER BY tong_gia_tri_trung_thau DESC
    LIMIT 10;

9. **So s√°nh gi√° tr·ªã th·∫ßu gi·ªØa c√°c th√°ng (month_comparison)**
- H·ªèi v√≠ d·ª•: "So s√°nh gi√° tr·ªã th·∫ßu trong th√°ng 9 v√† 10 v·ªõi trung b√¨nh 6 th√°ng ƒë·∫ßu nƒÉm"
- L∆∞u √Ω: Ph·∫£i t·ª± hi·ªÉu l√† ch·ªâ t√≠nh cho Viettel
- G·ª£i √Ω SQL:
  ```sql
    WITH 
    -- T·ªïng gi√° tr·ªã theo th√°ng (ch·ªâ Viettel)
    thau_theo_thang AS (
        SELECT 
            EXTRACT(MONTH FROM "Thoi_gian_phe_duyet") AS thang,
            SUM(CAST("Gi√°_tr√∫ng_th·∫ßu" AS DECIMAL)) AS tong_gia_tri,
            COUNT(*) AS so_goi
        FROM thau_2025
        WHERE 
            EXTRACT(YEAR FROM "Thoi_gian_phe_duyet") = 2025
            AND "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" = 'Viettel'
        GROUP BY EXTRACT(MONTH FROM "Thoi_gian_phe_duyet")
    ),

    -- Trung b√¨nh 6 th√°ng ƒë·∫ßu nƒÉm
    tb_6_thang_dau AS (
        SELECT 
            AVG(tong_gia_tri) AS tb_6_thang_dau_nam
        FROM thau_theo_thang
        WHERE thang BETWEEN 1 AND 6
    )

    SELECT 
        t10.so_goi AS so_goi_thang_10,
        t10.tong_gia_tri AS gia_tri_thang_10,
        t9.tong_gia_tri AS gia_tri_thang_9,
        tb.tb_6_thang_dau_nam,
        ROUND((t10.tong_gia_tri - t9.tong_gia_tri) / NULLIF(t9.tong_gia_tri, 0) * 100, 2) AS ty_le_tang_vs_thang9,
        ROUND((t10.tong_gia_tri - tb.tb_6_thang_dau_nam) / NULLIF(tb.tb_6_thang_dau_nam, 0) * 100, 2) AS ty_le_tang_vs_tb6
    FROM thau_theo_thang t10
    JOIN thau_theo_thang t9 ON t9.thang = 9
    CROSS JOIN tb_6_thang_dau tb
    WHERE t10.thang = 10;
  ```
- D√πng ƒë·ªÉ so s√°nh quy m√¥ gi√° tr·ªã v√† t·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng gi·ªØa th√°ng hi·ªán t·∫°i, th√°ng tr∆∞·ªõc v√† trung b√¨nh 6T ƒë·∫ßu nƒÉm

10. B√°o c√°o th·ªã ph·∫ßn lƒ©nh v·ª±c Ch√≠nh quy·ªÅn T·ªânh (provincial_gov_market_share)
- H·ªèi v√≠ d·ª•: "B√°o c√°o th·ªã ph·∫ßn lƒ©nh v·ª±c ch√≠nh quy·ªÅn t·ªânh"
- G·ª£i √Ω SQL:
    ```sql
    SELECT 
        "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" AS nhom,
        COUNT(*) AS so_goi,
        SUM(CAST("Gi√°_tr√∫ng_th·∫ßu" AS DECIMAL)) AS gia_tri,
        ROUND(SUM(CAST("Gi√°_tr√∫ng_th·∫ßu" AS DECIMAL)) 
            / NULLIF(
                (SELECT SUM(CAST("Gi√°_tr√∫ng_th·∫ßu" AS DECIMAL)) 
                FROM thau_2025 
                WHERE "Lƒ©nh_v·ª±c_Kh√°ch_h√†ng" = 'CQT' 
                AND EXTRACT(YEAR FROM "Thoi_gian_phe_duyet") = 2025
                AND "Thoi_gian_phe_duyet" < DATE_TRUNC('month', CURRENT_DATE)
                ), 0
            ) * 100, 2) AS thi_phan_phan_tram
    FROM thau_2025
    WHERE 
        "Lƒ©nh_v·ª±c_Kh√°ch_h√†ng" = 'CQT'
        AND EXTRACT(YEAR FROM "Thoi_gian_phe_duyet") = 2025
        AND "Thoi_gian_phe_duyet" < DATE_TRUNC('month', CURRENT_DATE)
    GROUP BY "Nh√≥m_tr√∫ng_th·∫ßu_shortlist"
    ORDER BY gia_tri DESC;
    ```
- D√πng ƒë·ªÉ t·∫°o b√°o c√°o chi ti·∫øt th·ªã ph·∫ßn Viettel, VNPT, FPT trong lƒ©nh v·ª±c ch√≠nh quy·ªÅn t·ªânh.

11. **G√≥i th·∫ßu l·ªõn nh·∫•t (largest_contract)**
- H·ªèi v√≠ d·ª•: 
  - "G√≥i th·∫ßu l·ªõn nh·∫•t c·ªßa VNPT l√† g√¨?"
  - "Cho t√¥i th√¥ng tin g√≥i th·∫ßu c√≥ gi√° tr·ªã cao nh·∫•t c·ªßa Viettel nƒÉm 2025"
- H∆∞·ªõng d·∫´n:
  - L·ªçc theo "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" t∆∞∆°ng ·ª©ng ('Viettel', 'VNPT', 'FPT', 'Kh√°c')
  - N·∫øu ng∆∞·ªùi d√πng ch·ªâ n√≥i "Viettel", c√≥ th·ªÉ match b·∫±ng ILIKE '%Viettel%' tr√™n "Nh√≥m_tr√∫ng_th·∫ßu"
  - C√≥ th·ªÉ th√™m ƒëi·ªÅu ki·ªán theo nƒÉm n·∫øu ƒë∆∞·ª£c nh·∫Øc ƒë·∫øn.
  - S·∫Øp x·∫øp gi·∫£m d·∫ßn theo "Gi√°_tr√∫ng_th·∫ßu" v√† l·∫•y LIMIT 1.
- G·ª£i √Ω SQL:
  ```sql
  SELECT 
      "S·ªë_th√¥ng_b√°o_m·ªùi_th·∫ßu",
      "T√™n_g√≥i_th·∫ßu",
      "T√™n_b√™n_tr√∫ng_th·∫ßu",
      "T√™n_b√™n_m·ªùi_th·∫ßu",
      "Gi√°_tr√∫ng_th·∫ßu",
      "Lƒ©nh_v·ª±c_Kh√°ch_h√†ng",
      "ƒê∆°n_v·ªã_kinh_doanh(VTS)",
      "Ph√¢n_lo·∫°i_s·∫£n_ph·∫©m",
      "H√¨nh_th·ª©c_LCNT",
      "Thoi_gian_phe_duyet",
      "NƒÉm_ph√™_duy·ªát_KQLCNT",
      "Th·ªùi_gian_ph√™_duy·ªát_KQLCNT"
  FROM thau_2025
  WHERE 
      "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" = 'VNPT'
      AND "Gi√°_tr√∫ng_th·∫ßu" IS NOT NULL
      AND "Gi√°_tr√∫ng_th·∫ßu" > 0
  ORDER BY "Gi√°_tr√∫ng_th·∫ßu" DESC
  LIMIT 1;
    ```

12. **So s√°nh k·∫øt qu·∫£ theo qu√Ω c√≥ ph·ª• thu·ªôc l·ªãch s·ª≠ h·ªôi tho·∫°i (quarter_comparison_with_history)**

CASE M·∫™U:

L∆∞·ª£t 1 ‚Äî User h·ªèi:
"so s√°nh s·ªë g√≥i v√† t·ªïng gi√° tr·ªã tr√∫ng th·∫ßu c·ªßa VTS qu√Ω 3 nƒÉm 2025 v·ªõi c√πng k·ª≥ nƒÉm ngo√°i"

‚Üí SQL chu·∫©n ph·∫£i t·∫°o:
SELECT 
    EXTRACT(YEAR FROM "Thoi_gian_phe_duyet") AS nam,
    COUNT(*) AS so_goi_thau,
    SUM("Gi√°_tr√∫ng_th·∫ßu") AS tong_gia_tri
FROM thau_2025
WHERE 
    "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" = 'Viettel'
    AND EXTRACT(MONTH FROM "Thoi_gian_phe_duyet") IN (7,8,9)
    AND EXTRACT(YEAR FROM "Thoi_gian_phe_duyet") IN (2024,2025)
    AND "Gi√°_tr√∫ng_th·∫ßu" IS NOT NULL
    AND "Gi√°_tr√∫ng_th·∫ßu" > 0
GROUP BY nam
ORDER BY nam;

Gi·∫£i th√≠ch:
- User n√≥i ‚ÄúVTS‚Äù ‚Üí mapping ch√≠nh x√°c ph·∫£i l√† "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" = 'Viettel'
- Qu√Ω 3 = th√°ng 7‚Äì9 ‚Üí d√πng EXTRACT(MONTH) IN (7,8,9)
- ‚Äúc√πng k·ª≥ nƒÉm ngo√°i‚Äù ‚Üí lu√¥n l·∫•y nƒÉm hi·ªán t·∫°i trong c√¢u h·ªèi v√† nƒÉm hi·ªán t·∫°i - 1
- D√πng Thoi_gian_phe_duyet (datetime) ƒë·ªÉ l·ªçc th·ªùi gian.
- GROUP BY theo nƒÉm ƒë·ªÉ c√≥ 2 d√≤ng: 2024 & 2025.

***

L∆∞·ª£t 2 ‚Äî User h·ªèi:
"th·∫ø c√≤n qu√Ω 2"

‚Üí Agent ph·∫£i hi·ªÉu:
- User KH√îNG nh·∫Øc l·∫°i ‚ÄúVTS‚Äù v√¨ ƒë√£ n√≥i ·ªü l∆∞·ª£t 1 ‚Üí ti·∫øp t·ª•c d√πng Viettel
- Kh√¥ng nh·∫Øc l·∫°i ‚Äú2025‚Äù nh∆∞ng ph·∫£i hi·ªÉu: v·∫´n so nƒÉm 2025 v√† 2024
- Ch·ªâ thay ƒë·ªïi qu√Ω ‚Üí d√πng th√°ng 4‚Äì6

‚Üí SQL chu·∫©n:
SELECT 
    EXTRACT(YEAR FROM "Thoi_gian_phe_duyet") AS nam,
    COUNT(*) AS so_goi_thau,
    SUM("Gi√°_tr√∫ng_th·∫ßu") AS tong_gia_tri
FROM thau_2025
WHERE 
    "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" = 'Viettel'
    AND EXTRACT(MONTH FROM "Thoi_gian_phe_duyet") IN (4,5,6)
    AND EXTRACT(YEAR FROM "Thoi_gian_phe_duyet") IN (2024,2025)
    AND "Gi√°_tr√∫ng_th·∫ßu" IS NOT NULL
    AND "Gi√°_tr√∫ng_th·∫ßu" > 0
GROUP BY nam
ORDER BY nam;

Nguy√™n t·∫Øc c·∫ßn ghi nh·ªõ cho m·ªçi tr∆∞·ªùng h·ª£p t∆∞∆°ng t·ª±:
- N·∫øu user ·ªü l∆∞·ª£t sau ch·ªâ thay ƒë·ªïi m·ªôt ph·∫ßn c√¢u h·ªèi (v√≠ d·ª•: ‚Äúth·∫ø c√≤n qu√Ω 2‚Äù, ‚Äúc√≤n th√°ng 8 th√¨ sao‚Äù, ‚Äúc√≤n FPT?‚Äù), agent ph·∫£i:
  1. K·∫ø th·ª´a to√†n b·ªô c·∫•u tr√∫c logic t·ª´ c√¢u h·ªèi tr∆∞·ªõc ƒë√≥  
  2. Ch·ªâ thay ƒë·ªïi duy nh·∫•t ph·∫ßn m√† user h·ªèi l·∫°i  
  3. Tuy·ªát ƒë·ªëi kh√¥ng reset √Ω nghƒ©a, kh√¥ng hi·ªÉu sang ng·ªØ c·∫£nh m·ªõi  

üëâ Trong m·ªçi tr∆∞·ªùng h·ª£p, tu√¢n th·ªß c√°c quy t·∫Øc SQL v√† quy tr√¨nh ReAct chu·∫©n:
- D√πng c·ªôt "Gi√°_tr√∫ng_th·∫ßu" (numeric) ƒë·ªÉ t√≠nh to√°n.
- D√πng "Thoi_gian_phe_duyet" cho ƒëi·ªÅu ki·ªán th·ªùi gian (NOT "Th·ªùi_gian_ph√™_duy·ªát_KQLCNT").
- C√°c nh√≥m nh√† th·∫ßu chu·∫©n: FPT, Viettel, VNPT, Kh√°c.
- K·∫øt qu·∫£ tr·∫£ l·ªùi ph·∫£i c√≥ s·ªë li·ªáu c·ª• th·ªÉ, kh√¥ng placeholder.
"""


# ============================================================================
# StreamBuffer, ErrorHandler, 
# ============================================================================

class StreamBuffer:
    """Buffer chunks for optimized streaming"""
    def __init__(self, buffer_size: int = 5):
        self.buffer = []
        self.buffer_size = buffer_size

    def add(self, chunk: str) -> Optional[str]:
        """Add chunk, return combined if buffer full"""
        self.buffer.append(chunk)
        if len(self.buffer) >= self.buffer_size:
            result = "".join(self.buffer)
            self.buffer = []
            return result
        return None

    def flush(self) -> str:
        """Flush remaining buffer"""
        result = "".join(self.buffer)
        self.buffer = []
        return result


class ErrorHandler:
    """Centralized error handling v·ªõi m√£ l·ªói"""
    
    @staticmethod
    def get_user_friendly_message(error: Exception, source_name: str = "") -> Tuple[str, str]:
        """
        Convert exception to user-friendly message + error code
        Returns: (message, error_code)
        """
        error_str = str(error).lower()
        
        # SQL Error
        if isinstance(error, (SQLAlchemyError, OperationalError, SQLTimeoutError)):
            logger.error(f"SQL error for {source_name}: {error}")
            return (
                f"L·ªói truy v·∫•n c∆° s·ªü d·ªØ li·ªáu. Vui l√≤ng th·ª≠ l·∫°i. (M√£ l·ªói: {ERROR_CODES['sql_error']})",
                ERROR_CODES['sql_error']
            )
        
        # Timeout Error
        if "timeout" in error_str or isinstance(error, asyncio.TimeoutError):
            logger.warning(f"Timeout for {source_name}: {error}")
            return (
                f"Truy v·∫•n m·∫•t qu√° nhi·ªÅu th·ªùi gian. Vui l√≤ng th·ª≠ l·∫°i. (M√£ l·ªói: {ERROR_CODES['timeout']})",
                ERROR_CODES['timeout']
            )
        
        # Rate Limit Error
        if isinstance(error, RateLimitError) or "rate limit" in error_str or "429" in error_str:
            logger.warning(f"Rate limit hit for {source_name}: {error}")
            return (
                f"H·ªá th·ªëng ƒëang qu√° t·∫£i. Vui l√≤ng th·ª≠ l·∫°i sau √≠t ph√∫t. (M√£ l·ªói: {ERROR_CODES['rate_limit']})",
                ERROR_CODES['rate_limit']
            )
        
        # Authentication Error
        if isinstance(error, AuthenticationError) or "authentication" in error_str or "401" in error_str:
            logger.error(f"Authentication error for {source_name}: {error}")
            return (
                f"L·ªói x√°c th·ª±c h·ªá th·ªëng. Vui l√≤ng li√™n h·ªá qu·∫£n tr·ªã vi√™n. (M√£ l·ªói: {ERROR_CODES['authentication']})",
                ERROR_CODES['authentication']
            )
        
        # Connection Error
        if isinstance(error, APIConnectionError) or "connection" in error_str:
            logger.error(f"Connection error for {source_name}: {error}")
            return (
                f"Kh√¥ng th·ªÉ k·∫øt n·ªëi t·ªõi h·ªá th·ªëng. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi m·∫°ng. (M√£ l·ªói: {ERROR_CODES['connection']})",
                ERROR_CODES['connection']
            )
        
        # General Error
        logger.error(f"General error for {source_name}: {error}")
        return (
            f"C√≥ l·ªói x·∫£y ra trong qu√° tr√¨nh x·ª≠ l√Ω. Vui l√≤ng th·ª≠ l·∫°i sau. (M√£ l·ªói: {ERROR_CODES['general']})",
            ERROR_CODES['general']
        )
    
    @staticmethod
    def should_retry(error: Exception) -> Tuple[bool, float]:
        """
        Determine if should retry and wait time
        Returns: (should_retry, wait_seconds)
        """
        error_str = str(error).lower()
        
        # Rate limit - extract wait time from error message
        if isinstance(error, RateLimitError) or "rate limit" in error_str:
            import re
            match = re.search(r'try again in (\d+)ms', error_str)
            if match:
                wait_ms = int(match.group(1))
                wait_seconds = (wait_ms / 1000.0) + 0.5
                return True, min(wait_seconds, 10.0)
            return True, 2.0
        
        # Connection errors - quick retry
        if isinstance(error, (APIConnectionError, OperationalError)) or "connection" in error_str or "timeout" in error_str:
            return True, 1.0
        
        # Don't retry auth errors
        return False, 0.0


# ============================================================================
# HSTAgent - Main Agent Class
# ============================================================================

class HSTAgent:
    """HST Agent with Text2SQL and ReAct mechanism"""
    
    DEFAULT_MODEL = "gpt-4.1"
    TIMEOUT_SECONDS = 120
    MAX_RETRIES = 3
    
    def __init__(
        self,
        source_name: str,
        db_connection_string: str,
        table_name: str,
        redis_client: redis.Redis,
        system_prompt: str = None,
        model: str = None
    ):
        """
        Initialize HST Agent
        
        Args:
            source_name: Name of the data source
            db_connection_string: Database connection string
            table_name: Table name to query
            redis_client: Redis client for caching
            system_prompt: Custom system prompt
            model: Model to use (default: gpt-4.1)
        """
        self.source_name = source_name
        self.db_connection_string = db_connection_string
        self.table_name = table_name
        self.redis_client = redis_client
        self.model = model or self.DEFAULT_MODEL
        self.model = self.model.split("/")[1] if "/" in self.model else self.model
        self.vector_store_id = "hst"
        logger.warning(f"Model for hst agent is {self.model}")
        
        # Initialize OpenAI client
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        # Initialize database engine
        self.engine = create_engine(
            db_connection_string,
            pool_pre_ping=True,
            pool_recycle=3600
        )
        
        # System prompt
        self.system_prompt = system_prompt or self._default_system_prompt()
    
        # Th·ªùi gian hi·ªán t·∫°i 
        now = datetime.now()
        self.current_date = now
        self.current_year = now.year
        self.current_month = now.month
        self.current_day = now.day

        logger.info(f"[TIME CONTEXT] Current date context initialized: {self.current_date}")

        # Initialize schema
        self._initialize_schema()
        
        logger.info(f"HST Agent initialized for {source_name} with table {table_name}")
    
    def _default_system_prompt(self) -> str:
        """Default system prompt for HST Agent"""
        return """B·∫°n l√† tr·ª£ l√Ω AI chuy√™n tr·∫£ l·ªùi c√¢u h·ªèi v·ªÅ h·ªì s∆° th·∫ßu (HST).
B·∫°n c√≥ kh·∫£ nƒÉng chuy·ªÉn ƒë·ªïi c√¢u h·ªèi ti·∫øng Vi·ªát th√†nh SQL query ƒë·ªÉ truy v·∫•n database.

Quy tr√¨nh ReAct:
1. THOUGHT: Ph√¢n t√≠ch c√¢u h·ªèi v√† x√°c ƒë·ªãnh th√¥ng tin c·∫ßn thi·∫øt
2. ACTION: Quy·∫øt ƒë·ªãnh h√†nh ƒë·ªông ti·∫øp theo (execute_query, final_answer)
3. OBSERVATION: Ph√¢n t√≠ch k·∫øt qu·∫£ t·ª´ h√†nh ƒë·ªông
4. L·∫∑p l·∫°i cho ƒë·∫øn khi b·∫°n CHO L√Ä ƒë√£ ƒë·ªß th√¥ng tin ƒë·ªÉ tr·∫£ l·ªùi

üí° L∆∞u √Ω:
- B·∫°n t·ª± quy·∫øt ƒë·ªãnh khi n√†o d√πng final_answer. N·∫øu th·∫•y ƒë·ªß d·ªØ li·ªáu/th√¥ng tin, h√£y tr·∫£ l·ªùi.
- Khi vi·∫øt final_answer, PH·∫¢I ch√®n c√°c con s·ªë c·ª• th·ªÉ (t·ªïng gi√° tr·ªã, % th·ªã ph·∫ßn, s·ªë h·ª£p ƒë·ªìng, v.v.)
- N·∫øu ch∆∞a c√≥ s·ªë, h√£y th·ª±c hi·ªán th√™m execute_query ho·∫∑c ph√©p t√≠nh trung gian (t·ªïng, chia, %).
    V√≠ d·ª•:
    ‚úÖ "T·ªïng gi√° tr·ªã NSNN l√† 1.230 t·ª∑ VND, VTS ƒë·∫°t 615 t·ª∑ (50%)."
    ‚ùå "T·ªïng gi√° tr·ªã l√† X ƒë·ªìng, VTS ƒë·∫°t Y ƒë·ªìng, chi·∫øm Z%."

üß≠ QUY T·∫ÆC CHO AGENT REACT:
- B·∫°n KH√îNG c·∫ßn vi·∫øt c√¢u tr·∫£ l·ªùi t·ª± nhi√™n trong final_answer.
- Khi b·∫°n ƒë√£ x√°c ƒë·ªãnh ƒë∆∞·ª£c SQL ƒë√∫ng, ƒë√£ th·ª±c thi query v√† d·ªØ li·ªáu tr·∫£ v·ªÅ h·ª£p l√Ω (c√≥ k·∫øt qu·∫£, kh√¥ng l·ªói),
  h√£y k·∫øt th√∫c b·∫±ng:
  ACTION: final_answer("ready")
- Agent ph√≠a sau s·∫Ω t·ª± t·ªïng h·ª£p b√°o c√°o chi ti·∫øt t·ª´ d·ªØ li·ªáu.

QUAN TR·ªåNG (PostgreSQL):
1. T√äN C·ªòT: S·ª≠ d·ª•ng CH√çNH X√ÅC t√™n c·ªôt t·ª´ schema (c√≥ d·∫•u, ch·ªØ hoa/th∆∞·ªùng ƒë√∫ng)
   
   ‚ö†Ô∏è PostgreSQL y√™u c·∫ßu DOUBLE QUOTES cho column names c√≥ d·∫•u/mixed case
   
   DANH S√ÅCH T√äN C·ªòT ƒê√öNG (lu√¥n wrap trong ""):
   ‚úÖ "Gi√°_tr√∫ng_th·∫ßu" (s·ªë, d√πng ƒë·ªÉ t√≠nh to√°n)
   ‚úÖ "Gi√°_tr√∫ng_th·∫ßu" (text, KH√îNG d√πng ƒë·ªÉ t√≠nh)
   ‚úÖ "Lƒ©nh_v·ª±c_Kh√°ch_h√†ng"
   ‚úÖ "Th·ªùi_gian_ph√™_duy·ªát_KQLCNT" (c√≥ _KQLCNT ·ªü cu·ªëi)
   ‚úÖ "NƒÉm_ph√™_duy·ªát_KQLCNT" (c√≥ _KQLCNT ·ªü cu·ªëi)
   ‚úÖ "ƒê∆°n_v·ªã_kinh_doanh(VTS)" (c√≥ (VTS) ·ªü cu·ªëi)
   ‚úÖ "Nh√≥m_tr√∫ng_th·∫ßu"
   ‚úÖ "T√™n_b√™n_tr√∫ng_th·∫ßu"
   ‚úÖ "T√™n_b√™n_m·ªùi_th·∫ßu"
   ‚úÖ "T√™n_g√≥i_th·∫ßu"
   
   V√ç D·ª§ SQL ƒê√öNG (v·ªõi double quotes):
   SELECT "Gi√°_tr√∫ng_th·∫ßu", "Nh√≥m_tr√∫ng_th·∫ßu" FROM table
   WHERE "Th·ªùi_gian_ph√™_duy·ªát_KQLCNT" = 'Th√°ng 10'
   
   SAI TH∆Ø·ªúNG G·∫∂P:
   ‚ùå Gi√°_tr√∫ng_th·∫ßu (no quotes) ‚Üí SYNTAX ERROR
   ‚ùå 'Gi√°_tr√∫ng_th·∫ßu' (single quotes) ‚Üí ERROR
   ‚úÖ "Gi√°_tr√∫ng_th·∫ßu" (double quotes) ‚Üí CORRECT
   
2. STRING LITERALS: D√πng d·∫•u nh√°y ƒë∆°n cho values (NOT column names)
   ‚úÖ ƒê√öNG: WHERE "Nh√≥m_tr√∫ng_th·∫ßu" = 'VTS'
   ‚ùå SAI: WHERE Nh√≥m_tr√∫ng_th·∫ßu = 'VTS' - missing quotes on column
   
3. ACTION FORMAT: T√™n c·ªôt KH√îNG C·∫¶N quotes trong action parameter
   ‚úÖ ƒê√öNG: get_distinct_values("Th·ªùi_gian_ph√™_duy·ªát_KQLCNT")
   ‚ö†Ô∏è NOTE: Code s·∫Ω t·ª± th√™m double quotes khi generate SQL
   
4. KI·ªÇM TRA SQL TR∆Ø·ªöC KHI EXECUTE:
   - Column names wrapped trong double quotes ""
   - String values wrapped trong single quotes ''
   - Kh√¥ng c√≥ empty column name
""" + "\n\n" + GENERAL_GUIDE_COMBINED
    
    def _initialize_schema(self):
        """Initialize database schema information with metadata"""
        try:
            # Get schema from database
            inspector = inspect(self.engine)
            columns = inspector.get_columns(self.table_name)
            
            # Enrich with metadata
            enriched_columns = []
            for col in columns:
                col_name = col["name"]
                col_info = {
                    "name": col_name,
                    "type": str(col["type"]),
                    "nullable": col.get("nullable", True)
                }
                
                # Add metadata if available
                if col_name in SCHEMA_METADATA:
                    col_info.update(SCHEMA_METADATA[col_name])
                
                enriched_columns.append(col_info)
            
            self.schema_info = {
                "table_name": self.table_name,
                "columns": enriched_columns
            }
            
            logger.info(f"Initialized enriched schema for {self.source_name}")
            
        except Exception as e:
            logger.error(f"Failed to initialize schema: {e}")
            self.schema_info = {"table_name": self.table_name, "columns": []}
    
    def _get_sample_rows(self, limit: int = 5) -> List[Dict]:
        """Get sample rows from database"""
        try:
            # Query database
            query = text(f"SELECT * FROM {self.table_name} LIMIT {limit}")
            logger.info(f"[SQL SAMPLES] SELECT * FROM {self.table_name} LIMIT {limit}")
            
            with self.engine.connect() as conn:
                result = conn.execute(query)
                samples = []
                for row in result:
                    mapped = {}
                    for k, v in dict(row._mapping).items():
                        if isinstance(v, datetime):
                            mapped[k] = v.isoformat(sep=" ", timespec="seconds")
                        else:
                            mapped[k] = v
                    samples.append(mapped)
            
            logger.info(f"[SQL SAMPLES SUCCESS] Retrieved {len(samples)} sample rows")
            return samples
            
        except Exception as e:
            logger.error(f"[SQL SAMPLES FAILED] Failed to get sample rows: {e}")
            return []
    
    def _get_distinct_values(self, column_name: str, limit: int = 50) -> List[Any]:
        """Get distinct values for a column"""
        try:
            # PostgreSQL requires double quotes for column names with special chars or mixed case
            # Wrap column name in double quotes
            quoted_column = f'"{column_name}"'
            query = text(f'SELECT DISTINCT {quoted_column} FROM {self.table_name} WHERE {quoted_column} IS NOT NULL LIMIT {limit}')
            
            # Log the query
            logger.info(f'[SQL DISTINCT] SELECT DISTINCT {quoted_column} FROM {self.table_name} WHERE {quoted_column} IS NOT NULL LIMIT {limit}')
            
            with self.engine.connect() as conn:
                result = conn.execute(query)
                values = [row[0] for row in result]
            
            logger.info(f"[SQL DISTINCT SUCCESS] Found {len(values)} distinct values for '{column_name}'")
            return values
            
        except Exception as e:
            logger.error(f"[SQL DISTINCT FAILED] Failed to get distinct values for {column_name}: {e}")
            return []
    
    def _validate_sql(self, sql_query: str) -> Tuple[bool, Optional[str]]:
        """
        Validate SQL query before execution
        Returns: (is_valid, error_message)
        """
        try:
            # Check for empty/whitespace query
            if not sql_query or not sql_query.strip():
                return False, "Empty SQL query"
            
            # Check parentheses balance
            if sql_query.count('(') != sql_query.count(')'):
                return False, "Unbalanced parentheses"
            
            # Check for common column name mistakes (case-insensitive patterns)
            
            # Pattern 1: Wrong column names
            common_mistakes = {
                'gi√°_tr√∫ng_th·∫ßu': 'Gi√°_tr√∫ng_th·∫ßu',
                'gia_trung_thau': 'Gi√°_tr√∫ng_th·∫ßu',  # Missing d·∫•u
                'lƒ©nh_v·ª±c_kh√°ch_h√†ng': 'Lƒ©nh_v·ª±c_Kh√°ch_h√†ng',
                'linh_vuc_khach_hang': 'Lƒ©nh_v·ª±c_Kh√°ch_h√†ng',
                'th·ªùi_gian_ph√™_duy·ªát_kqlcnt': 'Th·ªùi_gian_ph√™_duy·ªát_KQLCNT',
                'thoi_gian_phe_duyet_kqlcnt': 'Th·ªùi_gian_ph√™_duy·ªát_KQLCNT',
                'th·ªùi_gian_ph√™_duy·ªát': 'Th·ªùi_gian_ph√™_duy·ªát_KQLCNT',  # Thi·∫øu _KQLCNT
                'thoi_gian_phe_duyet': 'Th·ªùi_gian_ph√™_duy·ªát_KQLCNT',
                'ƒë∆°n_v·ªã_kinh_doanh': 'ƒê∆°n_v·ªã_kinh_doanh(VTS)',
                'don_vi_kinh_doanh': 'ƒê∆°n_v·ªã_kinh_doanh(VTS)',
                'nƒÉm_ph√™_duy·ªát_kqlcnt': 'NƒÉm_ph√™_duy·ªát_KQLCNT',
                'nam_phe_duyet_kqlcnt': 'NƒÉm_ph√™_duy·ªát_KQLCNT'
            }
            
            for wrong, correct in common_mistakes.items():
                # Use word boundary to avoid false positives
                import re
                pattern = r'\b' + re.escape(wrong) + r'\b'
                if re.search(pattern, sql_query):
                    return False, f"Wrong column name: use '{correct}' instead of '{wrong}'"
            
            # G·ª£i √Ω thay th·∫ø b·∫±ng DATE_TRUNC
            if 'Thoi_gian_phe_duyet' not in sql_query and 'CURRENT_DATE' in sql_query:
                logger.warning("[SQL VALIDATION] C·∫£nh b√°o: c√≥ th·ªÉ c·∫ßn d√πng Thoi_gian_phe_duyet cho ƒëi·ªÅu ki·ªán th·ªùi gian.")
            
            return True, None
            
        except Exception as e:
            logger.warning(f"SQL validation error: {e}")
            return True, None  # Don't block if validator fails
    
    def _execute_sql(self, sql_query: str) -> Tuple[List[Dict], Optional[str]]:
        """Execute SQL query with validation and automatic scalar handling"""
        is_valid, validation_error = self._validate_sql(sql_query)
        if not is_valid:
            error_msg = f"SQL Validation Error: {validation_error}"
            logger.error(error_msg)
            return [], error_msg

        logger.info(f"[SQL EXECUTING] {sql_query}")

        try:
            with self.engine.connect() as conn:
                # Clean escape characters if accidentally added
                sql_query = sql_query.replace('\\"', '"').replace("\\'", "'")

                # Detect if it's a single-value aggregate
                is_scalar_query = bool(
                    re.search(r'\b(SUM|AVG|COUNT|MAX|MIN)\b', sql_query, re.IGNORECASE)
                    and not re.search(r'\bGROUP\s+BY\b', sql_query, re.IGNORECASE)
                )

                if is_scalar_query:
                    scalar_val = conn.scalar(text(sql_query))
                    if scalar_val is None:
                        scalar_val = 0.0
                    try:
                        scalar_val = float(scalar_val)
                    except Exception:
                        scalar_val = float(str(scalar_val).replace(",", "")) if scalar_val else 0.0
                    logger.info(f"[SQL SCALAR] Result: {scalar_val:,.2f}")
                    return ([{"column": "value", "value": scalar_val, "formatted": f"{scalar_val:,.2f}"}], None)

                # Normal multi-row query
                result = conn.execute(text(sql_query))
                rows = []
                for row in result:
                    mapped = {}
                    for k, v in dict(row._mapping).items():
                        # Force convert Decimal / memoryview / bytearray / None to float
                        if isinstance(v, (Decimal, memoryview, bytearray)):
                            try:
                                mapped[k] = float(str(v))
                            except Exception:
                                mapped[k] = None
                        elif isinstance(v, (int, float)):
                            mapped[k] = float(v)
                        elif v is None:
                            mapped[k] = 0.0
                        else:
                            try:
                                mapped[k] = float(v) if str(v).replace('.', '', 1).isdigit() else v
                            except Exception:
                                mapped[k] = v
                    rows.append(mapped)

                # Handle single-row numeric fallback
                if len(rows) == 1 and len(rows[0]) == 1:
                    key, val = list(rows[0].items())[0]
                    try:
                        val = float(val or 0)
                    except Exception:
                        val = 0.0
                    logger.info(f"[SQL SINGLE NUMERIC] {key}: {val:,.2f}")
                    return ([{"column": key, "value": val, "formatted": f"{val:,.2f}"}], None)

                logger.info(f"[SQL SUCCESS] Returned {len(rows)} rows")
                return rows, None

        except Exception as e:
            err = f"SQL Execution Error: {e}"
            logger.error(f"[SQL FAILED] {err}")
            return [], err
        
    async def _execute_sql_async(self, sql: str):
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, lambda: self._execute_sql(sql))
    
    async def run_queries_parallel(self, queries: list[dict]):
        tasks = []
        for q in queries:
            tasks.append(self._execute_sql_async(q["sql"]))
        results = await asyncio.gather(*tasks)
        merged = []
        for idx, (rows, error) in enumerate(results):
            merged.append({
                "id": queries[idx].get("id"),
                "description": queries[idx].get("description"),
                "error": error,
                "rows": rows
            })
        return merged

    
    def _create_react_prompt(self, question: str, react_history: List[Dict] = None) -> str:
        """Create ReAct prompt with schema metadata and guides"""
        
        # Schema information v·ªõi metadata
        schema_str = json.dumps(self.schema_info, ensure_ascii=False, indent=2)
        
        # Sample rows
        samples = self._get_sample_rows(3)
        samples_str = json.dumps(samples, ensure_ascii=False, indent=2)

        # D√πng to√†n b·ªô h∆∞·ªõng d·∫´n chung
        general_guides = GENERAL_GUIDE_COMBINED

        # ReAct history
        history_str = ""
        if react_history:
            history_str = "\n\nL·ªãch s·ª≠ c√°c b∆∞·ªõc ƒë√£ th·ª±c hi·ªán:\n"
            for i, step in enumerate(react_history, 1):
                history_str += f"B∆∞·ªõc {i}:\n"
                history_str += f"  THOUGHT: {step.get('thought', '')}\n"
                history_str += f"  ACTION: {step.get('action', '')}\n"
                history_str += f"  OBSERVATION: {step.get('observation', '')}\n"
        
        prompt = f"""Database Schema (c√≥ metadata m√¥ t·∫£ √Ω nghƒ©a t·ª´ng c·ªôt):
{schema_str}

Sample Data (3 d√≤ng m·∫´u):
{samples_str}

{general_guides}

Available Actions:
- get_distinct_values(column_name): L·∫•y c√°c gi√° tr·ªã unique c·ªßa m·ªôt c·ªôt
- execute_query(sql): Th·ª±c thi SQL query
- final_answer(answer): ƒê∆∞a ra c√¢u tr·∫£ l·ªùi cu·ªëi c√πng

Question: {question}
{history_str}

H√£y s·ª≠ d·ª•ng quy tr√¨nh ReAct ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi. V·ªõi m·ªói b∆∞·ªõc:
1. THOUGHT: Suy nghƒ© v·ªÅ nh·ªØng g√¨ c·∫ßn l√†m d·ª±a tr√™n metadata v√† general guide
2. ACTION: Quy·∫øt ƒë·ªãnh h√†nh ƒë·ªông ti·∫øp theo (execute_query, final_answer)
3. OBSERVATION: Ph√¢n t√≠ch k·∫øt qu·∫£ t·ª´ h√†nh ƒë·ªông

H√£y b·∫Øt ƒë·∫ßu v·ªõi THOUGHT ƒë·∫ßu ti√™n:
"""
        
        return prompt
    
    def _parse_react_response(self, response_text: str) -> Tuple[str, str, str]:
        """
        Parse ReAct response - handles multiline ACTION
        Returns: (action_type, action_param, thought)
        """
        import re
        
        thought = ""
        action_type = ""
        action_param = ""
        
        # Extract THOUGHT
        thought_match = re.search(r'THOUGHT:\s*(.+?)(?=ACTION:|$)', response_text, re.DOTALL)
        if thought_match:
            thought = thought_match.group(1).strip()
        
        # Extract ACTION (may span multiple lines)
        action_match = re.search(r'ACTION:\s*(.+?)(?=OBSERVATION:|THOUGHT:|$)', response_text, re.DOTALL)
        if not action_match:
            return "", "", thought
        
        action_text = action_match.group(1).strip()
        
        # Parse action type and parameter
        if "get_distinct_values" in action_text:
            action_type = "get_distinct_values"
            # Extract column name
            match = re.search(r'get_distinct_values\s*\(\s*["\']([^"\']+)["\']\s*\)', action_text)
            if match:
                action_param = match.group(1).strip()
            else:
                # Without quotes
                match = re.search(r'get_distinct_values\s*\(\s*([^\)]+)\s*\)', action_text)
                if match:
                    action_param = match.group(1).strip()
            
            # Validate
            if not action_param or not action_param.strip():
                logger.warning(f"Empty column name parsed from: {action_text[:100]}")
                action_type = ""
                
        elif "execute_query" in action_text:
            action_type = "execute_query"
            
            # Log what we're trying to parse
            logger.info(f"[REACT PARSE] Attempting to parse execute_query from: {action_text[:200]}...")
            
            # Clean action_text - remove extra whitespace/newlines between function call
            cleaned = re.sub(r'execute_query\s*\(\s*', 'execute_query(', action_text)
            
            # Pattern 1: execute_query("SQL") or execute_query('SQL')
            match = re.search(r'execute_query\(["\'](.+?)["\']\)', cleaned, re.DOTALL)
            if match:
                action_param = match.group(1).strip()
                logger.info(f"[REACT PARSE] Pattern 1 matched, SQL length: {len(action_param)}")
            else:
                # Pattern 2: execute_query( "SQL" ) with spaces
                match = re.search(r'execute_query\(\s*["\'](.+?)["\']\s*\)', action_text, re.DOTALL)
                if match:
                    action_param = match.group(1).strip()
                    logger.info(f"[REACT PARSE] Pattern 2 matched, SQL length: {len(action_param)}")
                else:
                    # Pattern 3: Try greedy match - everything between ( and last )
                    match = re.search(r'execute_query\s*\((.+)\)', action_text, re.DOTALL)
                    if match:
                        sql = match.group(1).strip()
                        # Remove surrounding quotes if any
                        if (sql.startswith('"') and sql.endswith('"')) or (sql.startswith("'") and sql.endswith("'")):
                            sql = sql[1:-1]
                        action_param = sql.strip()
                        logger.info(f"[REACT PARSE] Pattern 3 (greedy) matched, SQL length: {len(action_param)}")
                    else:
                        # Pattern 4: Incomplete - missing closing paren
                        logger.error(f"[REACT PARSE] Failed to parse execute_query")
                        logger.error(f"[REACT PARSE] Action text: {action_text}")
            
            # Validate
            if not action_param or not action_param.strip():
                logger.warning(f"Empty SQL parsed from: {action_text[:200]}")
                action_type = ""
            else:
                logger.info(f"[REACT PARSE SUCCESS] Extracted SQL: {action_param[:100]}...")
                
        elif "final_answer" in action_text:
            action_type = "final_answer"
            # Extract answer
            match = re.search(r'final_answer\s*\(\s*["\'](.+?)["\']\s*\)', action_text, re.DOTALL)
            if match:
                action_param = match.group(1).strip()
            else:
                # Without quotes
                match = re.search(r'final_answer\s*\(\s*(.+?)\s*\)\s*$', action_text, re.DOTALL)
                if match:
                    answer = match.group(1).strip()
                    if (answer.startswith('"') and answer.endswith('"')) or (answer.startswith("'") and answer.endswith("'")):
                        answer = answer[1:-1]
                    action_param = answer.strip()
        
        return action_type, action_param, thought


    async def query_agentic(self, question: str):
        """
        Agentic V2:
        1. Planner draft k·∫ø ho·∫°ch
        2. SQL Agent ch·∫°y song song
        3. Summarizer vi·∫øt b√°o c√°o
        """

        # 1. PLANNER
        planner = PlannerAgent(model=self.model)
        plan = planner.plan(question, self.schema_info)

        if "queries" not in plan:
            return "‚ùå Planner l·ªói: kh√¥ng th·ªÉ l·∫≠p k·∫ø ho·∫°ch.", plan

        queries = plan["queries"]

        # 2. SQL EXECUTOR (parallel)
        sql_results = await self.run_queries_parallel(queries)

        # 3. SUMMARIZER
        summarizer = SummarizerAgent(model=self.model)
        final_report = summarizer.summarize(
            question=question,
            sql_query=json.dumps(queries, ensure_ascii=False),
            sql_results=sql_results,
            scenario=plan.get("scenario")
        )

        return final_report, {
            "plan": plan,
            "sql_results": sql_results
        }

    def query(
        self,
        question: str,
        conversation_history: List[Dict[str, Any]] = None,
        model: str = None,
        max_react_steps: int = 20
    ) -> Generator[str, None, Dict[str, Any]]:
        """
        Query with ReAct mechanism - streaming response
        
        Args:
            question: User question
            conversation_history: Conversation history
            model: Model to use
            max_react_steps: Maximum ReAct steps
            
        Yields:
            Response chunks (text)
            
        Returns:
            Final metadata dict with usage info
        """
        start_time = time.time()
        # ============================================================
        # AUTO-DETECT: N·∫øu c√¢u h·ªèi c·∫ßn multi-query ‚Üí chuy·ªÉn sang agentic
        # ============================================================
        planner = PlannerAgent(model=self.model or self.DEFAULT_MODEL)
        scenario = planner.classify(question)
        
        # N·∫øu l√† scenario_1, scenario_2, ho·∫∑c scenario_3 ‚Üí d√πng agentic mode
        if scenario in ["scenario_1", "scenario_2", "scenario_3"]:
            logger.info(f"[AUTO-DETECT] Question matches {scenario} ‚Üí switching to AGENTIC mode")
            
            # Stream th√¥ng b√°o cho user
            yield "üîç ƒêang ph√¢n t√≠ch c√¢u h·ªèi v√† l·∫≠p k·∫ø ho·∫°ch th·ª±c thi...\n\n"
            import asyncio
            import concurrent.futures
            try:
                # Check if there's a running loop
                try:
                    loop = asyncio.get_running_loop()
                    # Loop is running - use thread pool
                    use_thread = True
                except RuntimeError:
                    # No running loop - we can create one
                    use_thread = False
                
                if use_thread:
                    # Run in a separate thread with its own event loop
                    def run_in_new_loop():
                        new_loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(new_loop)
                        try:
                            return new_loop.run_until_complete(self.query_agentic(question))
                        finally:
                            new_loop.close()
                    
                    with concurrent.futures.ThreadPoolExecutor() as executor:
                        future = executor.submit(run_in_new_loop)
                        final_report, metadata = future.result()
                        # ‚úÖ FIX 1: Stream report ra user
                        buffer = StreamBuffer(buffer_size=5)
                        for char in final_report:
                            buffered = buffer.add(char)
                            if buffered:
                                yield buffered
                        remaining = buffer.flush()
                        if remaining:
                            yield remaining

                        # ‚úÖ FIX 2: RETURN ƒë·ªÉ d·ª´ng execution (CRITICAL!)
                        return metadata  # ‚Üê TH√äM D√íNG N√ÄY!
                else:
                    # No running loop, create and use one
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    try:
                        final_report, metadata = loop.run_until_complete(self.query_agentic(question))
                    finally:
                        loop.close()
                        
            except Exception as e:
                logger.error(f"Event loop error: {e}")
                yield "‚ö†Ô∏è C√≥ l·ªói x·∫£y ra trong qu√° tr√¨nh x·ª≠ l√Ω. Vui l√≤ng th·ª≠ l·∫°i sau. (M√£ l·ªói: 99)\n"
                return {"error": str(e), "error_code": "99"}
        
        # N·∫øu kh√¥ng ph·∫£i multi-query scenario ‚Üí ti·∫øp t·ª•c ReAct mode
        logger.info(f"[AUTO-DETECT] Question is '{scenario}' ‚Üí using REACT mode")

        react_history = []
        full_response = ""
        total_prompt_tokens = 0
        total_completion_tokens = 0
    
        try:
            for step in range(max_react_steps):
                logger.info(f"[REACT STEP {step+1}/{max_react_steps}] Starting...")
                
                # Create prompt
                prompt = self._create_react_prompt(question, react_history)
                
                # Call LLM
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": self.system_prompt},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.1,
                    max_tokens=2000
                )
                
                response_text = response.choices[0].message.content
                logger.debug(f"[REACT RAW STEP OUTPUT]\n{response_text}")
                total_prompt_tokens += response.usage.prompt_tokens
                total_completion_tokens += response.usage.completion_tokens
                
                # Parse ReAct response
                action_type, action_param, thought = self._parse_react_response(response_text)
                
                logger.info(f"[REACT STEP {step+1}] Action: {action_type}, Thought: {thought[:100]}...")
                
                if action_type == "get_distinct_values":
                    # Get distinct values
                    logger.info(f"[REACT ACTION] get_distinct_values('{action_param}')")
                    values = self._get_distinct_values(action_param)
                    observation = f"Distinct values: {values[:20]}"  # Limit to 20
                    react_history.append({
                        "thought": thought,
                        "action": f"get_distinct_values({action_param})",
                        "observation": observation
                    })
                    
                elif action_type == "execute_query":
                    logger.info(f"[REACT ACTION] execute_query('{action_param[:100]}...')")
                    results, error = self._execute_sql(action_param)
                    if error:
                        observation = f"Error: {error}"
                        logger.warning(f"[REACT ACTION FAILED] SQL error: {error}")
                    else:
                        # Kh√¥ng c·∫Øt ch·ªâ "First row", gi·ªØ to√†n b·ªô d·ªØ li·ªáu
                        observation = f"Query returned {len(results)} rows with full dataset attached."
                        logger.info(f"[REACT ACTION SUCCESS] Returned {len(results)} rows (full data retained).")
                    
                    react_history.append({
                        "thought": thought,
                        "action": f"execute_query({action_param})",
                        "observation": observation,
                        "results": results if not error else []
                    })
                        
                elif action_type == "final_answer":
                    logger.info("[REACT FINAL] Detected final_answer trigger ‚Äî skipping LLM-generated text.")
                    
                    # Lu√¥n t√¨m k·∫øt qu·∫£ query cu·ªëi c√πng c√≥ d·ªØ li·ªáu
                    last_exec = next(
                        (s for s in reversed(react_history)
                        if s.get("action", "").startswith("execute_query") and s.get("results")),
                        None
                    )

                    summarizer = SummarizerAgent(model=self.model)
                    if last_exec:
                        full_results = last_exec.get("results", [])
                        logger.info(f"[REACT FINAL] Feeding {len(full_results)} rows to summarizer for final report.")
                        try:
                            full_response = summarizer.summarize(
                                question,
                                last_exec.get("action", ""),
                                full_results,
                                scenario=None   # ReAct kh√¥ng c√≥ Planner
                            )
                            logger.info("[REACT FINAL] SummarizerAgent successfully generated final report.")
                        except Exception as e:
                            logger.error(f"[REACT FINAL] SummarizerAgent failed: {e}")
                            full_response = "Kh√¥ng th·ªÉ sinh b√°o c√°o t·ªïng h·ª£p do l·ªói Summarizer."
                    else:
                        logger.warning("[REACT FINAL] Kh√¥ng c√≥ d·ªØ li·ªáu execute_query ‚Äî kh√¥ng th·ªÉ t·ªïng h·ª£p b√°o c√°o.")
                        full_response = "Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu truy v·∫•n ƒë·ªÉ t·ªïng h·ª£p b√°o c√°o."

                    # Stream ra user
                    buffer = StreamBuffer(buffer_size=5)
                    for char in full_response:
                        buffered = buffer.add(char)
                        if buffered:
                            yield buffered
                    remaining = buffer.flush()
                    if remaining:
                        yield remaining
                    break
            
            # Create response ID
            response_id = f"hst_{int(time.time())}_{hashlib.md5(question.encode()).hexdigest()[:8]}"
            
            # Calculate usage
            usage = TokenUsage(
                prompt_tokens=total_prompt_tokens,
                completion_tokens=total_completion_tokens,
                total_tokens=total_prompt_tokens + total_completion_tokens,
                model=self.model
            )
            
            # Log
            log_openai_agent_response(
                response_id=response_id,
                source_name=self.source_name,
                vector_store_id="hst",
                user_query=question,
                assistant_response=full_response,
                model=self.model,
                usage=usage
            )
            
            return {
                "response_id": response_id,
                "usage": usage,
                "duration": time.time() - start_time,
                "source_name": self.source_name,
                "model": model,
                "react_steps": len(react_history)
            }
            
        except Exception as e:
            error_msg, error_code = ErrorHandler.get_user_friendly_message(e, self.source_name)
            logger.error(f"Query failed: {e}")
            
            yield f"\n\n‚ö†Ô∏è {error_msg}"
            
            log_openai_agent_error(
                source_name=self.source_name,
                vector_store_id="hst",
                model=self.model,
                user_query=question,
                error_message=str(e)
            )
            
            return {
                "error": error_msg,
                "error_code": error_code,
                "duration": time.time() - start_time,
                "source_name": self.source_name,
                "model": model
            }
    
    async def query_async(self, *args, **kwargs):
        """Async wrapper around sync query for API compatibility"""
        if kwargs.get("mode") == "agentic":
            async for out in self.query_agentic(*args, **kwargs):
                yield out
            return

        loop = asyncio.get_event_loop()
        def run_sync():
            results = []
            for chunk in self.query(*args, **kwargs):
                results.append(chunk)
            return results

        # Ch·∫°y sync query trong thread executor
        chunks = await loop.run_in_executor(None, run_sync)
        for c in chunks:
            yield c
    
    async def generate_title_from_message(self, message: str, model: str = None) -> Tuple[str, TokenUsage]:
        """Generate conversation title - async"""
        
        try:
            async_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            
            response = await async_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "T·∫°o ti√™u ƒë·ªÅ ng·∫Øn (‚â§10 t·ª´) cho cu·ªôc h·ªôi tho·∫°i v·ªÅ h·ªì s∆° th·∫ßu. Ch·ªâ tr·∫£ ti√™u ƒë·ªÅ."},
                    {"role": "user", "content": f"Ti√™u ƒë·ªÅ: {message[:200]}"}
                ],
                max_tokens=40,
                temperature=0.3
            )
            
            title = response.choices[0].message.content.strip().strip('"')
            usage = TokenUsage(
                prompt_tokens=response.usage.prompt_tokens,
                completion_tokens=response.usage.completion_tokens,
                total_tokens=response.usage.total_tokens,
                model=self.model
            )
            
            return title, usage
            
        except Exception as e:
            logger.error(f"Title generation failed: {str(e)}")
            return f"H·ªôi tho·∫°i {self.source_name.title()}", TokenUsage(model=self.model)
    
    async def generate_next_turn_suggestions(
        self, 
        conversation_history: List[Dict[str, Any]], 
        model: str = None
    ) -> Tuple[List[str], TokenUsage]:
        """Generate next turn suggestions - async"""
        
        try:
            async_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            
            recent_history = conversation_history[-2:]
            formatted_history = "\n".join([
                f"{msg['role'].capitalize()}: {msg['content'][:300]}"
                for msg in recent_history
            ])
            
            system_prompt = (
                "G·ª£i √Ω 3-5 c√¢u h·ªèi ti·∫øp theo v·ªÅ h·ªì s∆° th·∫ßu.\n"
                "JSON array. Kh√¥ng gi·∫£i th√≠ch.\n"
                "N·∫øu kh√¥ng ph√π h·ª£p ‚Üí []."
            )
            
            response = await async_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": formatted_history}
                ],
                max_tokens=300,
                temperature=0.3
            )
            
            suggestions_text = response.choices[0].message.content.strip()
            try:
                suggestions = json.loads(suggestions_text)
                if not isinstance(suggestions, list):
                    suggestions = []
            except:
                suggestions = []
            
            usage = TokenUsage(
                prompt_tokens=response.usage.prompt_tokens,
                completion_tokens=response.usage.completion_tokens,
                total_tokens=response.usage.total_tokens,
                model=self.model
            )
            
            return suggestions, usage
            
        except Exception as e:
            logger.error(f"Suggestions failed: {str(e)}")
            return [], TokenUsage(model=self.model)

class SummarizerAgent:
    """
    Agent t√≥m t·∫Øt k·∫øt qu·∫£ SQL th√†nh b√°o c√°o t·ª± nhi√™n.
    - T·∫≠p trung m√¥ t·∫£, so s√°nh d·ª±a tr√™n s·ªë li·ªáu.
    - Kh√¥ng ƒë∆∞a ra nh·∫≠n ƒë·ªãnh ch·ªß quan, d·ª± ƒëo√°n, khuy·∫øn ngh·ªã hay ph·∫ßn k√Ω t√™n.
    - Tr·ªçng t√¢m l√† g√≥c nh√¨n c·ªßa Viettel Solutions (VTS), so v·ªõi FPT v√† VNPT.
    """

    def __init__(self, model: str = "gpt-4.1"):
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.model = model

    def sanitize_json(self, obj):
        if isinstance(obj, datetime):
            return obj.isoformat()
        if isinstance(obj, Decimal):
            return float(obj)
        return obj

    def summarize(self, question: str, sql_query: str, sql_results: list[dict], scenario: str = None):
        """
        Sinh b√°o c√°o ti·∫øng Vi·ªát, kh√°ch quan, t·∫≠p trung v√†o s·ªë li·ªáu th·ª±c t·∫ø.
        """
        logger.info("=== DEBUG SUMMARIZER START ===")
        logger.info(f"SQL_RESULTS_RAW: {sql_results}")
        try:
            logger.info(f"SQL_RESULTS_KEYS: {[list(r.keys()) for r in sql_results]}")
        except Exception as e:
            logger.info(f"FAILED TO EXTRACT KEYS: {e}")

        if scenario:
            logger.info(f"[SUMMARIZER] Using forwarded scenario: {scenario}")
        else:
            scenario = self.detect_template(sql_results)

        if scenario == "scenario_1":
            template = open("src/agents/hst/templates/scenario_1.txt").read() 
        elif scenario == "scenario_2":
            template = open("src/agents/hst/templates/scenario_2.txt").read()
        elif scenario == "scenario_3":
            template = open("src/agents/hst/templates/scenario_3.txt").read()
        else:
            template = """
            H√£y t√≥m t·∫Øt ng·∫Øn g·ªçn d·ª±a tr√™n d·ªØ li·ªáu.
            Y√äU C·∫¶U TR√åNH B√ÄY:
1. **T·ªïng quan th·ªã tr∆∞·ªùng**: m√¥ t·∫£ quy m√¥, xu h∆∞·ªõng ch√≠nh (n·∫øu c√≥ th·ªÉ). L∆ØU √ù kh√¥ng n√≥i v·ªÅ nh√≥m 'KH√ÅC'.
2. **Chi ti·∫øt t·ª´ng b√™n**: tr√¨nh b√†y k·∫øt qu·∫£ theo b·∫£ng (s·ªë g√≥i, gi√° tr·ªã, t·ª∑ tr·ªçng).
3. **K·∫øt lu·∫≠n**: K·∫øt lu·∫≠n ng·∫Øn g·ªçn (kh√¥ng suy di·ªÖn, h·∫°n ch·∫ø nh·∫Øc l·∫°i √Ω ·ªü ph·∫ßn 1). L∆ØU √ù kh√¥ng n√≥i v·ªÅ nh√≥m 'KH√ÅC'.
            """
            
        prompt = f"""
B·∫°n l√† chuy√™n gia ph√¢n t√≠ch d·ªØ li·ªáu ƒë·∫•u th·∫ßu c·ªßa Viettel Solutions (VTS).
H√£y vi·∫øt b√°o c√°o t√≥m t·∫Øt d·ª±a ho√†n to√†n tr√™n d·ªØ li·ªáu ƒë∆∞·ª£c cung c·∫•p ‚Äî KH√îNG ƒë∆∞·ª£c suy di·ªÖn, d·ª± ƒëo√°n ho·∫∑c ƒë∆∞a ra nh·∫≠n ƒë·ªãnh ch·ªß quan.

C√¢u h·ªèi ng∆∞·ªùi d√πng: {question}

H√£y tr·∫£ v·ªÅ b√°o c√°o ƒë√∫ng format template sau:

{template}

SQL ƒë∆∞·ª£c th·ª±c thi:
{sql_query}

K·∫øt qu·∫£ d·ªØ li·ªáu SQL (JSON):
{json.dumps(sql_results, default=self.sanitize_json, ensure_ascii=False, indent=2)}

H∆Ø·ªöNG D·∫™N B·ªî SUNG:
- ∆Øu ti√™n tr√¨nh b√†y k·∫øt qu·∫£ ·ªü d·∫°ng b·∫£ng, d·ªÖ ƒë·ªçc.
- C√°c s·ªë li·ªáu ƒë·∫ßu ra ƒë·ªÅu t√≠nh theo **t·ª∑ Vi·ªát Nam ƒê·ªìng (t·ª∑ VND)**.
- Tr·ªçng t√¢m l√† hi·ªáu qu·∫£ v√† v·ªã th·∫ø c·ªßa Viettel Solutions (VTS), so v·ªõi FPT v√† VNPT n·∫øu c√≥ d·ªØ li·ªáu.
- Nh√≥m ‚ÄúKh√°c‚Äù ch·ªâ c·∫ßn n√™u t·ªïng gi√° tr·ªã v√† t·ª∑ tr·ªçng, kh√¥ng ƒëi s√¢u chi ti·∫øt.
- Tuy·ªát ƒë·ªëi kh√¥ng th√™m ph·∫ßn "Khuy·∫øn ngh·ªã", "Ghi ch√∫", ho·∫∑c "Ph√≤ng Ph√¢n t√≠ch d·ªØ li·ªáu".

QUY T·∫ÆC ƒê·ªäNH D·∫†NG S·ªê:
- D·ªØ li·ªáu ƒë·∫ßu v√†o c√≥ d·∫•u th·∫≠p ph√¢n l√† "." (v√≠ d·ª•: 100100.1).
- Khi hi·ªÉn th·ªã trong b√°o c√°o, chuy·ªÉn sang ƒë·ªãnh d·∫°ng ti·∫øng Vi·ªát:
  + D·∫•u ph√¢n c√°ch ph·∫ßn th·∫≠p ph√¢n l√† ",".
  + D·∫•u ph√¢n c√°ch h√†ng ngh√¨n, h√†ng tri·ªáu, t·ª∑ l√† ".".
  V√≠ d·ª•: 100100.1 ‚Üí 100.100,1
- ƒê·∫£m b·∫£o ƒë·ªãnh d·∫°ng n√†y √°p d·ª•ng nh·∫•t qu√°n cho t·∫•t c·∫£ s·ªë li·ªáu trong b√°o c√°o.
"""
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {
                    "role": "system",
                    "content": "B·∫°n l√† chuy√™n gia ph√¢n t√≠ch d·ªØ li·ªáu ƒë·∫•u th·∫ßu c·ªßa Viettel Solutions, ch·ªâ m√¥ t·∫£ v√† so s√°nh s·ªë li·ªáu, kh√¥ng ƒë∆∞·ª£c ƒë∆∞a ra nh·∫≠n ƒë·ªãnh ch·ªß quan hay khuy·∫øn ngh·ªã."
                },
                {"role": "user", "content": prompt}
            ],
            temperature=0.15,
            max_tokens=900
        )
        return response.choices[0].message.content.strip()

    def detect_template(self, sql_results):
            """
            Nh·∫≠n di·ªán template d·ª±a v√†o metadata c·ªßa planner ho·∫∑c c·∫•u tr√∫c d·ªØ li·ªáu t·ª´ ReAct,
            KH√îNG b·∫Øt bu·ªôc ph·∫£i c√≥ field 'id' trong t·ª´ng row SQL.
            
            Logic:
            - N·∫øu c√≥ field 'id' ‚Üí d√πng logic c≈© (Planner mode)
            - N·∫øu kh√¥ng c√≥ 'id' ‚Üí ph√¢n t√≠ch c·∫•u tr√∫c d·ªØ li·ªáu (ReAct mode)
            """
            logger.info("=== DEBUG detect_template START ===")
            logger.info(f"INPUT sql_results: {sql_results}")

            if not sql_results:
                logger.error("detect_template: EMPTY sql_results ‚Üí return 'other'")
                return "other"

            try:
                all_keys = [list(r.keys()) for r in sql_results]
                logger.info(f"detect_template: KEYS OF ROWS ‚Üí {all_keys}")
            except Exception as e:
                logger.error(f"detect_template: FAILED TO LIST KEYS: {e}")
                return "other"

            # Ki·ªÉm tra xem c√≥ field 'id' kh√¥ng
            first_row_keys = list(sql_results[0].keys()) if sql_results else []
            has_id_field = "id" in first_row_keys
            
            logger.info(f"detect_template: has_id_field = {has_id_field}")

            # ============================================================
            # PLANNER MODE: N·∫øu c√≥ field 'id', d√πng logic c≈©
            # ============================================================
            if has_id_field:
                logger.info("detect_template: Using PLANNER MODE (id-based detection)")
                
                try:
                    if any(r.get("id") == "nsnn" for r in sql_results):
                        logger.info("MATCH scenario_1")
                        return "scenario_1"
                except Exception as e:
                    logger.error(f"detect_template ERROR at scenario_1: {e}")

                try:
                    if any(r.get("id") == "viettel_overview" for r in sql_results):
                        logger.info("MATCH scenario_2")
                        return "scenario_2"
                except Exception as e:
                    logger.error(f"detect_template ERROR at scenario_2: {e}")

                try:
                    if any(str(r.get("id", "")).startswith("obj_") for r in sql_results):
                        logger.info("MATCH scenario_3")
                        return "scenario_3"
                except Exception as e:
                    logger.error(f"detect_template ERROR at scenario_3: {e}")

                logger.info("detect_template: PLANNER MODE ‚Üí RETURN 'other'")
                return "other"

            # ============================================================
            # REACT MODE: Ph√¢n t√≠ch d·ª±a tr√™n c·∫•u tr√∫c d·ªØ li·ªáu
            # ============================================================
            logger.info("detect_template: Using REACT MODE (structure-based detection)")
            
            # L·∫•y t·∫•t c·∫£ c√°c keys t·ª´ k·∫øt qu·∫£ SQL
            all_column_names = set()
            for row in sql_results:
                all_column_names.update(row.keys())
            
            logger.info(f"detect_template: All column names found: {all_column_names}")
            
            # Scenario 1: Market overview - c√≥ nhi·ªÅu nh√≥m tr√∫ng th·∫ßu v√† ph√¢n kh√∫c
            # ƒê·∫∑c ƒëi·ªÉm: c√≥ tr∆∞·ªùng "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" ho·∫∑c nhi·ªÅu rows v·ªõi c√°c nh√≥m kh√°c nhau
            scenario_1_indicators = {
                "Nh√≥m_tr√∫ng_th·∫ßu_shortlist",
                "market_total",
                "nsnn",
                "khdn"
            }
            
            # Scenario 2: Viettel detail analysis
            # ƒê·∫∑c ƒëi·ªÉm: c√≥ tr∆∞·ªùng li√™n quan ƒë·∫øn th√°ng, ƒêVKD, ho·∫∑c so s√°nh v·ªõi FPT/VNPT
            scenario_2_indicators = {
                "thang",
                "dvkd", 
                "ƒê∆°n_v·ªã_kinh_doanh(VTS)",
                "by_month",
                "by_center"
            }
            
            # Scenario 3: Specific object analysis (province, sector, unit)
            # ƒê·∫∑c ƒëi·ªÉm: c√≥ tr∆∞·ªùng t·ªânh, lƒ©nh v·ª±c, ho·∫∑c ph√¢n t√≠ch theo ƒë·ªëi t∆∞·ª£ng c·ª• th·ªÉ
            scenario_3_indicators = {
                "M√£_t·ªânh_m·ªõi",
                "M√£_t·ªânh_c≈©",
                "Lƒ©nh_v·ª±c_Kh√°ch_h√†ng",
                "obj_monthly"
            }
            
            # Ki·ªÉm tra overlap v·ªõi c√°c indicators
            s1_match = len(all_column_names & scenario_1_indicators)
            s2_match = len(all_column_names & scenario_2_indicators)
            s3_match = len(all_column_names & scenario_3_indicators)
            
            logger.info(f"detect_template: scenario_1 matches: {s1_match}")
            logger.info(f"detect_template: scenario_2 matches: {s2_match}")
            logger.info(f"detect_template: scenario_3 matches: {s3_match}")
            
            # Quy·∫øt ƒë·ªãnh scenario d·ª±a tr√™n s·ªë l∆∞·ª£ng match
            if s1_match > 0 and s1_match >= s2_match and s1_match >= s3_match:
                logger.info("detect_template: REACT MODE ‚Üí scenario_1 (market overview)")
                return "scenario_1"
            elif s2_match > 0 and s2_match > s1_match and s2_match >= s3_match:
                logger.info("detect_template: REACT MODE ‚Üí scenario_2 (viettel detail)")
                return "scenario_2"
            elif s3_match > 0:
                logger.info("detect_template: REACT MODE ‚Üí scenario_3 (specific object)")
                return "scenario_3"
            
            # Ki·ªÉm tra d·ª±a tr√™n s·ªë l∆∞·ª£ng rows v√† c√≥ GROUP BY
            # N·∫øu c√≥ nhi·ªÅu rows v·ªõi "Nh√≥m_tr√∫ng_th·∫ßu" ‚Üí likely market share query
            if "Nh√≥m_tr√∫ng_th·∫ßu" in all_column_names and len(sql_results) > 2:
                logger.info("detect_template: REACT MODE ‚Üí scenario_1 (detected market share pattern)")
                return "scenario_1"
            
            # N·∫øu c√≥ "thang" (month) ‚Üí time series analysis, likely scenario 2
            if "thang" in all_column_names:
                logger.info("detect_template: REACT MODE ‚Üí scenario_2 (detected time series)")
                return "scenario_2"
            
            logger.info("detect_template: REACT MODE ‚Üí RETURN 'other'")
            return "other"


class PlannerAgent:
    """
    Planner Agent:
    - Nh·∫≠n user query
    - Ph√¢n lo·∫°i v√†o 4 scenario
    - Sinh danh s√°ch SQL queries t∆∞∆°ng ·ª©ng
    """

    def __init__(self, model="gpt-4.1"):
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.model = model
        self.allowed_scenarios = ["scenario_1", "scenario_2", "scenario_3", "other"]

    # =========================
    # 1. LLM-based classifier
    # =========================
    def _classify_llm(self, question: str) -> str:
        """
        D√πng LLM ƒë·ªÉ ph√¢n lo·∫°i intent.
        Ch·ªâ ƒë∆∞·ª£c tr·∫£ v·ªÅ 1 trong 4 chu·ªói:
        - scenario_1
        - scenario_2
        - scenario_3
        - other
        """
        try:
            system_prompt = """
B·∫°n l√† h·ªá th·ªëng ph√¢n lo·∫°i intent cho tr·ª£ l√Ω h·ªì s∆° th·∫ßu (HST). 
Nhi·ªám v·ª•: D·ª±a tr√™n c√¢u h·ªèi ti·∫øng Vi·ªát c·ªßa ng∆∞·ªùi d√πng, ph√¢n lo·∫°i v√†o ƒë√∫ng M·ªòT trong 4 nh√≥m sau:

===========================================================
üéØ **scenario_1 ‚Äî B√°o c√°o TH·ªä PH·∫¶N T·ªîNG QUAN / TO√ÄN TH·ªä TR∆Ø·ªúNG**
===========================================================
Mi√™u t·∫£:
- Ng∆∞·ªùi d√πng h·ªèi v·ªÅ to√†n th·ªã tr∆∞·ªùng n√≥i chung, *kh√¥ng* t·∫≠p trung v√†o Viettel.
- Th·ªùi gian c√≥ th·ªÉ l√† th√°ng c·ª• th·ªÉ, l≈©y k·∫ø, ho·∫∑c nhi·ªÅu th√°ng.
- C√≥ th·ªÉ y√™u c·∫ßu t·ªïng h·ª£p, c·∫≠p nh·∫≠t, xu h∆∞·ªõng chung c·ªßa th·ªã tr∆∞·ªùng.

D·∫•u hi·ªáu:
- ‚Äúth·ªã ph·∫ßn th·∫ßu n√≥i chung‚Äù, ‚Äút·ªïng quan th·ªã tr∆∞·ªùng‚Äù, ‚Äúb√°o c√°o th·ªã ph·∫ßn‚Äù, 
  ‚Äút·ªïng h·ª£p th·ªã ph·∫ßn‚Äù, ‚Äút√¨nh h√¨nh th·ªã ph·∫ßn‚Äù, ‚Äúto√†n th·ªã tr∆∞·ªùng‚Äù.
- KH√îNG nh·∫Øc t·ªõi Viettel ho·∫∑c DVKD/t·ªânh c·ª• th·ªÉ.

V√≠ d·ª• ƒë√∫ng scenario_1:
- ‚ÄúB√°o c√°o th·ªã ph·∫ßn th·∫ßu l≈©y k·∫ø 10 th√°ng‚Äù
- ‚ÄúT·ªïng h·ª£p th·ªã ph·∫ßn th·∫ßu th√°ng 9/2025‚Äù
- ‚ÄúB√°o c√°o th·ªã ph·∫ßn c√°c th√°ng 6 7 8‚Äù
- ‚ÄúC·∫≠p nh·∫≠t th·ªã ph·∫ßn th·∫ßu 34 t·ªânh‚Äù
- ‚ÄúXu h∆∞·ªõng th·ªã ph·∫ßn to√†n th·ªã tr∆∞·ªùng nƒÉm 2025‚Äù

V√≠ d·ª• KH√îNG ph·∫£i scenario_1:
- ‚ÄúB√°o c√°o th·ªã ph·∫ßn Viettel th√°ng 10‚Äù ‚Üí scenario_2
- ‚ÄúTop ƒêVKD c·ªßa Viettel‚Äù ‚Üí scenario_3
- ‚ÄúTh·ªã ph·∫ßn t·ªânh H√† N·ªôi th√°ng 9‚Äù ‚Üí scenario_3


===========================================================
üéØ **scenario_2 ‚Äî B√°o c√°o TH·ªä PH·∫¶N CHI TI·∫æT CHO VIETTEL**
===========================================================
Mi√™u t·∫£:
- Ng∆∞·ªùi d√πng h·ªèi v·ªÅ k·∫øt qu·∫£ ho·∫∑c th·ªã ph·∫ßn c·ªßa **Viettel (VTS)**.
- Tr·ªçng t√¢m l√† Viettel so v·ªõi ƒë·ªëi th·ªß (FPT, VNPT, GAET,‚Ä¶).
- C√¢u h·ªèi ch·ªâ nh·∫Øm v√†o Viettel, kh√¥ng nh·∫Øm v√†o m·ªôt ƒë∆°n v·ªã/t·ªânh/lƒ©nh v·ª±c c·ª• th·ªÉ.

D·∫•u hi·ªáu:
- ‚ÄúViettel‚Äù, ‚ÄúVTS‚Äù, ‚ÄúViettel Solutions‚Äù, ‚Äúth·ªã ph·∫ßn c·ªßa Viettel‚Äù.
- H·ªèi ri√™ng v·ªÅ Viettel ho·∫∑c so s√°nh Viettel v·ªõi ƒë∆°n v·ªã kh√°c.

V√≠ d·ª• ƒë√∫ng scenario_2:
- ‚ÄúB√°o c√°o th·ªã ph·∫ßn th·∫ßu th√°ng 10 c·ªßa Viettel‚Äù
- ‚ÄúHi·ªáu su·∫•t c·ªßa Viettel trong qu√Ω 2‚Äù
- ‚ÄúSo s√°nh th·ªã ph·∫ßn Viettel v·ªõi FPT v√† VNPT‚Äù
- ‚ÄúT·ªïng gi√° tr·ªã tr√∫ng th·∫ßu c·ªßa Viettel l≈©y k·∫ø 9 th√°ng‚Äù

V√≠ d·ª• KH√îNG ph·∫£i scenario_2:
- ‚ÄúB√°o c√°o th·ªã ph·∫ßn ƒêVKD mi·ªÅn Nam c·ªßa Viettel‚Äù ‚Üí scenario_3
- ‚ÄúTh·ªã ph·∫ßn t·ªânh H√† N·ªôi c·ªßa Viettel‚Äù ‚Üí scenario_3
- ‚ÄúB√°o c√°o th·ªã ph·∫ßn to√†n th·ªã tr∆∞·ªùng‚Äù ‚Üí scenario_1


===========================================================
üéØ **scenario_3 ‚Äî B√°o c√°o THEO ƒê·ªêI T∆Ø·ª¢NG C·ª§ TH·ªÇ**
===========================================================
Mi√™u t·∫£:
- C√¢u h·ªèi nh·∫Øm v√†o m·ªôt **dimension c·ª• th·ªÉ** nh∆∞:
  ‚ñ∏ ƒê∆°n v·ªã kinh doanh (ƒêVKD)  
  ‚ñ∏ T·ªânh / Th√†nh ph·ªë  
  ‚ñ∏ Lƒ©nh v·ª±c kh√°ch h√†ng   
- D√π c√≥ ho·∫∑c kh√¥ng nh·∫Øc t·ªõi Viettel.

D·∫•u hi·ªáu:
- ‚Äút·ªânh‚Äù, ‚Äúth√†nh ph·ªë‚Äù, ‚ÄúH√† N·ªôi‚Äù, ‚Äúƒê√† N·∫µng‚Äù
- ‚ÄúƒêVKD‚Äù, ‚Äútrung t√¢m‚Äù, ‚ÄúTT CQƒêT‚Äù, ‚ÄúKHDN‚Äù
- ‚Äúlƒ©nh v·ª±c kh√°ch h√†ng‚Äù, ‚ÄúYTS‚Äù, ‚ÄúGDS‚Äù, ‚ÄúCQT‚Äù, ‚ÄúBQP‚Äù

V√≠ d·ª• ƒë√∫ng scenario_3:
- ‚ÄúB√°o c√°o th·ªã ph·∫ßn th·∫ßu th√°ng 10 c·ªßa H√† N·ªôi‚Äù
- ‚ÄúB√°o c√°o th·ªã ph·∫ßn nh√≥m ƒêVKD TT CQƒêT‚Äù
- ‚ÄúTh·ªã ph·∫ßn lƒ©nh v·ª±c YTS nƒÉm 2025‚Äù
- ‚ÄúB√°o c√°o th·ªã ph·∫ßn ƒê√† N·∫µng th√°ng 9‚Äù
- ‚ÄúTh·ªã ph·∫ßn ph√¢n kh√∫c CQT c·ªßa Viettel‚Äù

V√≠ d·ª• KH√îNG ph·∫£i scenario_3:
- ‚ÄúB√°o c√°o th·ªã ph·∫ßn Viettel nƒÉm 2025‚Äù ‚Üí scenario_2
- ‚ÄúT·ªïng quan th·ªã ph·∫ßn l≈©y k·∫ø‚Äù ‚Üí scenario_1


===========================================================
üéØ **other ‚Äî Kh√¥ng thu·ªôc 3 nh√≥m tr√™n**
===========================================================
Mi√™u t·∫£:
- M·ªçi c√¢u h·ªèi kh√¥ng thu·ªôc v·ªÅ 3 nh√≥m tr√™n.

===========================================================
‚ö†Ô∏è QUY T·∫ÆC ∆ØU TI√äN PH√ÇN LO·∫†I (VERY IMPORTANT)
===========================================================
1. N·∫øu c√¢u h·ªèi nh·∫Øc r√µ Viettel ‚Üí ∆∞u ti√™n scenario_2  
   *Tr·ª´ khi nh·∫Øc r√µ m·ªôt ƒë·ªëi t∆∞·ª£ng c·ª• th·ªÉ (t·ªânh/ƒêVKD/lƒ©nh v·ª±c) ‚Üí scenario_3.*

2. N·∫øu c√¢u h·ªèi c√≥ t·ªânh/ƒêVKD/lƒ©nh v·ª±c ‚Üí scenario_3  
   *D√π c√≥ ho·∫∑c kh√¥ng nh·∫Øc Viettel.*

3. N·∫øu kh√¥ng nh·∫Øc ƒë·ªëi t∆∞·ª£ng c·ª• th·ªÉ & kh√¥ng nh·∫•n m·∫°nh Viettel ‚Üí scenario_1.

4. Lu√¥n tr·∫£ v·ªÅ duy nh·∫•t m·ªôt chu·ªói:  
   üëâ ‚Äúscenario_1‚Äù, ‚Äúscenario_2‚Äù, ‚Äúscenario_3‚Äù ho·∫∑c ‚Äúother‚Äù.

5. Kh√¥ng gi·∫£i th√≠ch th√™m b·∫•t k·ª≥ n·ªôi dung n√†o.


===========================================================
CH·ªà TR·∫¢ V·ªÄ:
scenario_1
ho·∫∑c
scenario_2
ho·∫∑c
scenario_3
ho·∫∑c
other
===========================================================
"""

            resp = self.client.chat.completions.create(
                model=self.model,
                temperature=0.0,
                max_tokens=10,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": question},
                ],
            )

            label = resp.choices[0].message.content.strip()
            # Chu·∫©n h√≥a
            label = label.split()[0]  # ph√≤ng tr∆∞·ªùng h·ª£p model l·ª° n√≥i th√™m g√¨ ƒë√≥
            if label not in self.allowed_scenarios:
                return "other"
            return label

        except Exception as e:
            logger.error(f"[PLANNER] LLM classify failed: {e}")
            return "other"

    # =========================
    # 2. Public API
    # =========================
    def classify(self, question: str) -> str:
        scenario = self._classify_llm(question)
        return scenario


    # =========================
    # 3. Planner logic (gi·ªØ nguy√™n)
    # =========================
    def plan(self, question: str, schema):
        scenario = self.classify(question)

        if scenario == "scenario_1":
            return self._plan_scenario_1()

        if scenario == "scenario_2":
            return self._plan_scenario_2()

        if scenario == "scenario_3":
            return self._plan_scenario_3(question)

        return {"scenario": "other", "queries": []}
    
    def _plan_scenario_1(self):
        queries = [
            {
                "id": "market_total",
                "description": "T·ªïng s·ªë g√≥i + t·ªïng gi√° tr·ªã to√†n th·ªã tr∆∞·ªùng",
                "sql": """
                    SELECT 
                        COUNT(*) AS so_goi,
                        SUM("Gi√°_tr√∫ng_th·∫ßu") AS tong_gia_tri
                    FROM thau_2025
                    WHERE "Gi√°_tr√∫ng_th·∫ßu" > 0
                    AND "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" != 'Kh√°c'
                """
            },
            {
                "id": "market_by_vendor",
                "description": "T·ªïng gi√° tr·ªã theo nh√≥m tr√∫ng th·∫ßu",
                "sql": """
                    SELECT 
                        "Nh√≥m_tr√∫ng_th·∫ßu_shortlist",
                        COUNT(*) AS so_goi,
                        SUM("Gi√°_tr√∫ng_th·∫ßu") AS gia_tri
                    FROM thau_2025
                    WHERE "Gi√°_tr√∫ng_th·∫ßu" > 0
                    AND "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" != 'Kh√°c'
                    GROUP BY "Nh√≥m_tr√∫ng_th·∫ßu_shortlist"
                    ORDER BY gia_tri DESC
                """
            },
            {
                "id": "nsnn",
                "description": "Gi√° tr·ªã theo nh√≥m NSNN",
                "sql": """
                    SELECT 
                        "Nh√≥m_tr√∫ng_th·∫ßu_shortlist",
                        COUNT(*) AS so_goi,
                        SUM("Gi√°_tr√∫ng_th·∫ßu") AS gia_tri
                    FROM thau_2025
                    WHERE "Gi√°_tr√∫ng_th·∫ßu" > 0
                        AND "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" != 'Kh√°c'
                        AND "Lƒ©nh_v·ª±c_Kh√°ch_h√†ng" IN ('TW','BQP','CQT','YTS','GDS')
                    GROUP BY "Nh√≥m_tr√∫ng_th·∫ßu_shortlist"
                    ORDER BY gia_tri DESC
                """
            },
            {
                "id": "khdn",
                "description": "Kh·ªëi doanh nghi·ªáp",
                "sql": """
                    SELECT 
                        "Nh√≥m_tr√∫ng_th·∫ßu_shortlist",
                        COUNT(*) AS so_goi,
                        SUM("Gi√°_tr√∫ng_th·∫ßu") AS gia_tri
                    FROM thau_2025
                    WHERE "Gi√°_tr√∫ng_th·∫ßu" > 0
                        AND "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" != 'Kh√°c'
                        AND "Lƒ©nh_v·ª±c_Kh√°ch_h√†ng" = 'KHDN'
                    GROUP BY "Nh√≥m_tr√∫ng_th·∫ßu_shortlist"
                    ORDER BY gia_tri DESC
                """
            },
            {
                "id": "kenh_truyen",
                "description": "D·ªãch v·ª• k√™nh truy·ªÅn",
                "sql": """
                    SELECT 
                        "Nh√≥m_tr√∫ng_th·∫ßu_shortlist",
                        COUNT(*) AS so_goi,
                        SUM("Gi√°_tr√∫ng_th·∫ßu") AS gia_tri
                    FROM thau_2025
                    WHERE "Gi√°_tr√∫ng_th·∫ßu" > 0
                        AND "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" != 'Kh√°c'
                        AND "Ph√¢n_lo·∫°i_s·∫£n_ph·∫©m" = 'K√™nh truy·ªÅn'
                    GROUP BY "Nh√≥m_tr√∫ng_th·∫ßu_shortlist"
                    ORDER BY gia_tri DESC
                """
            }
        ]
        return {"scenario": "scenario_1", "queries": queries}
    
    def _plan_scenario_2(self):
        """
        Scenario 2: B√°o c√°o th·ªã ph·∫ßn chi ti·∫øt c·ªßa Viettel
        Y√™u c·∫ßu ƒë·∫ßy ƒë·ªß c√°c queries theo template scenario_2.txt
        """
        return {
            "scenario": "scenario_2",
            "queries": [
                # 1. T·ªîNG QUAN VIETTEL
                {
                    "id": "viettel_overview",
                    "description": "T·ªïng quan Viettel: s·ªë g√≥i, t·ªïng gi√° tr·ªã, th·ªã ph·∫ßn, x·∫øp h·∫°ng",
                    "sql": """
                        WITH market_total AS (
                            SELECT 
                                SUM("Gi√°_tr√∫ng_th·∫ßu") AS tong_thi_truong
                            FROM thau_2025
                            WHERE "Gi√°_tr√∫ng_th·∫ßu" > 0
                                AND "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" != 'Kh√°c'
                        ),
                        viettel_data AS (
                            SELECT 
                                COUNT(*) AS so_goi,
                                SUM("Gi√°_tr√∫ng_th·∫ßu") AS gia_tri
                            FROM thau_2025
                            WHERE "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" = 'Viettel'
                                AND "Gi√°_tr√∫ng_th·∫ßu" > 0
                        ),
                        vendor_ranking AS (
                            SELECT 
                                "Nh√≥m_tr√∫ng_th·∫ßu_shortlist",
                                SUM("Gi√°_tr√∫ng_th·∫ßu") AS gia_tri,
                                RANK() OVER (ORDER BY SUM("Gi√°_tr√∫ng_th·∫ßu") DESC) AS rank
                            FROM thau_2025
                            WHERE "Gi√°_tr√∫ng_th·∫ßu" > 0
                                AND "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" != 'Kh√°c'
                            GROUP BY "Nh√≥m_tr√∫ng_th·∫ßu_shortlist"
                        )
                        SELECT 
                            vd.so_goi,
                            vd.gia_tri,
                            ROUND(CAST(vd.gia_tri * 100.0 / mt.tong_thi_truong AS NUMERIC), 1) AS market_share,
                            vr.rank
                        FROM viettel_data vd
                        CROSS JOIN market_total mt
                        LEFT JOIN vendor_ranking vr ON vr."Nh√≥m_tr√∫ng_th·∫ßu_shortlist" = 'Viettel'
                    """
                },
                
                # 2. Lƒ®NH V·ª∞C VIETTEL ƒê·ª®NG S·ªê 1
                {
                    "id": "fields_rank1",
                    "description": "Danh s√°ch lƒ©nh v·ª±c Viettel ƒë·ª©ng h·∫°ng 1",
                    "sql": """
                        WITH field_ranking AS (
                            SELECT 
                                "Lƒ©nh_v·ª±c_Kh√°ch_h√†ng",
                                "Nh√≥m_tr√∫ng_th·∫ßu_shortlist",
                                SUM("Gi√°_tr√∫ng_th·∫ßu") AS gia_tri,
                                RANK() OVER (
                                    PARTITION BY "Lƒ©nh_v·ª±c_Kh√°ch_h√†ng" 
                                    ORDER BY SUM("Gi√°_tr√∫ng_th·∫ßu") DESC
                                ) AS rank
                            FROM thau_2025
                            WHERE "Gi√°_tr√∫ng_th·∫ßu" > 0
                                AND "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" != 'Kh√°c'
                                AND "Lƒ©nh_v·ª±c_Kh√°ch_h√†ng" IS NOT NULL
                            GROUP BY "Lƒ©nh_v·ª±c_Kh√°ch_h√†ng", "Nh√≥m_tr√∫ng_th·∫ßu_shortlist"
                        )
                        SELECT 
                            "Lƒ©nh_v·ª±c_Kh√°ch_h√†ng" AS linh_vuc,
                            gia_tri
                        FROM field_ranking
                        WHERE "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" = 'Viettel'
                            AND rank = 1
                        ORDER BY gia_tri DESC
                    """
                },
                
                # 3. Lƒ®NH V·ª∞C VIETTEL CH∆ØA ƒê·ª®NG S·ªê 1
                {
                    "id": "fields_not_rank1",
                    "description": "Danh s√°ch lƒ©nh v·ª±c Viettel ch∆∞a ƒë·ª©ng h·∫°ng 1",
                    "sql": """
                        WITH field_ranking AS (
                            SELECT 
                                "Lƒ©nh_v·ª±c_Kh√°ch_h√†ng",
                                "Nh√≥m_tr√∫ng_th·∫ßu_shortlist",
                                SUM("Gi√°_tr√∫ng_th·∫ßu") AS gia_tri,
                                RANK() OVER (
                                    PARTITION BY "Lƒ©nh_v·ª±c_Kh√°ch_h√†ng" 
                                    ORDER BY SUM("Gi√°_tr√∫ng_th·∫ßu") DESC
                                ) AS rank
                            FROM thau_2025
                            WHERE "Gi√°_tr√∫ng_th·∫ßu" > 0
                                AND "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" != 'Kh√°c'
                                AND "Lƒ©nh_v·ª±c_Kh√°ch_h√†ng" IS NOT NULL
                            GROUP BY "Lƒ©nh_v·ª±c_Kh√°ch_h√†ng", "Nh√≥m_tr√∫ng_th·∫ßu_shortlist"
                        ),
                        viettel_fields AS (
                            SELECT 
                                "Lƒ©nh_v·ª±c_Kh√°ch_h√†ng" AS linh_vuc,
                                gia_tri AS viettel_gia_tri,
                                rank AS viettel_rank
                            FROM field_ranking
                            WHERE "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" = 'Viettel'
                        ),
                        top_vendor AS (
                            SELECT 
                                "Lƒ©nh_v·ª±c_Kh√°ch_h√†ng" AS linh_vuc,
                                "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" AS top_vendor_name,
                                gia_tri AS top_gia_tri
                            FROM field_ranking
                            WHERE rank = 1
                        )
                        SELECT 
                            vf.linh_vuc,
                            vf.viettel_gia_tri,
                            vf.viettel_rank,
                            tv.top_vendor_name,
                            tv.top_gia_tri
                        FROM viettel_fields vf
                        LEFT JOIN top_vendor tv ON vf.linh_vuc = tv.linh_vuc
                        WHERE vf.viettel_rank > 1
                        ORDER BY vf.viettel_rank, vf.viettel_gia_tri DESC
                    """
                },
                
                # 4. TOP 3 T·ªàNH C√ì TH·ªä PH·∫¶N CAO NH·∫§T
                {
                    "id": "top_provinces",
                    "description": "Top 3 t·ªânh c√≥ th·ªã ph·∫ßn Viettel cao nh·∫•t",
                    "sql": """
                        WITH province_total AS (
                            SELECT 
                                "M√£_t·ªânh_m·ªõi",
                                SUM("Gi√°_tr√∫ng_th·∫ßu") AS tong_tinh
                            FROM thau_2025
                            WHERE "Gi√°_tr√∫ng_th·∫ßu" > 0
                                AND "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" != 'Kh√°c'
                                AND "M√£_t·ªânh_m·ªõi" IS NOT NULL
                            GROUP BY "M√£_t·ªânh_m·ªõi"
                        ),
                        viettel_by_province AS (
                            SELECT 
                                "M√£_t·ªânh_m·ªõi",
                                SUM("Gi√°_tr√∫ng_th·∫ßu") AS viettel_gia_tri
                            FROM thau_2025
                            WHERE "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" = 'Viettel'
                                AND "Gi√°_tr√∫ng_th·∫ßu" > 0
                                AND "M√£_t·ªânh_m·ªõi" IS NOT NULL
                            GROUP BY "M√£_t·ªânh_m·ªõi"
                        )
                        SELECT 
                            vp."M√£_t·ªânh_m·ªõi" AS tinh,
                            ROUND(CAST(vp.viettel_gia_tri * 100.0 / pt.tong_tinh AS NUMERIC), 1) AS thi_phan
                        FROM viettel_by_province vp
                        LEFT JOIN province_total pt ON vp."M√£_t·ªânh_m·ªõi" = pt."M√£_t·ªânh_m·ªõi"
                        WHERE pt.tong_tinh > 0
                        ORDER BY thi_phan DESC
                        LIMIT 3
                    """
                },
                
                # 5. TOP 5 ƒêVKD
                {
                    "id": "top_dvkd",
                    "description": "Top 5 ƒêVKD theo gi√° tr·ªã tr√∫ng th·∫ßu",
                    "sql": """
                        SELECT 
                            "ƒê∆°n_v·ªã_kinh_doanh(VTS)" AS dvkd,
                            COUNT(*) AS so_goi,
                            SUM("Gi√°_tr√∫ng_th·∫ßu") AS gia_tri
                        FROM thau_2025
                        WHERE "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" = 'Viettel'
                            AND "Gi√°_tr√∫ng_th·∫ßu" > 0
                        GROUP BY dvkd
                        ORDER BY gia_tri DESC
                        LIMIT 5
                    """
                },
                
                # 6. GI√Å TR·ªä THEO TH√ÅNG
                {
                    "id": "by_month",
                    "description": "Gi√° tr·ªã Viettel theo t·ª´ng th√°ng",
                    "sql": """
                        SELECT 
                            EXTRACT(MONTH FROM "Thoi_gian_phe_duyet") AS thang,
                            SUM("Gi√°_tr√∫ng_th·∫ßu") AS gia_tri,
                            COUNT(*) AS so_goi
                        FROM thau_2025
                        WHERE "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" = 'Viettel'
                            AND "Gi√°_tr√∫ng_th·∫ßu" > 0
                        GROUP BY thang
                        ORDER BY thang
                    """
                },
                
                # 7. GI√Å TR·ªä L≈®Y K·∫æ THEO TH√ÅNG
                {
                    "id": "by_month_lk",
                    "description": "Gi√° tr·ªã l≈©y k·∫ø theo th√°ng",
                    "sql": """
                        WITH monthly_data AS (
                            SELECT 
                                EXTRACT(MONTH FROM "Thoi_gian_phe_duyet") AS thang,
                                SUM("Gi√°_tr√∫ng_th·∫ßu") AS gia_tri
                            FROM thau_2025
                            WHERE "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" = 'Viettel'
                                AND "Gi√°_tr√∫ng_th·∫ßu" > 0
                            GROUP BY thang
                        )
                        SELECT 
                            thang,
                            SUM(gia_tri) OVER (ORDER BY thang) AS gia_tri_luy_ke
                        FROM monthly_data
                        ORDER BY thang
                    """
                }
            ]
        }

    def _extract_scenario3_object_via_llm(self, question: str):
        """
        D√πng LLM ƒë·ªÉ tr√≠ch xu·∫•t ƒë·ªëi t∆∞·ª£ng cho scenario_3:
        - ƒêVKD (ƒê∆°n v·ªã kinh doanh Viettel)
        - T·ªânh / Th√†nh ph·ªë
        - Lƒ©nh v·ª±c kh√°ch h√†ng

        Tr·∫£ v·ªÅ:
            target_name: t√™n hi·ªÉn th·ªã cho user (H√† N·ªôi, TT CQƒêT, lƒ©nh v·ª±c YTS, ...)
            search_field: 'dvkd' | 'province' | 'field' | 'unknown'
            search_value: gi√° tr·ªã d√πng ƒë·ªÉ search (ƒë√£ lower + escape quote)
        """
        import json
        import re

        system_prompt = """
B·∫°n ƒëang h·ªó tr·ª£ h·ªá th·ªëng ph√¢n t√≠ch h·ªì s∆° th·∫ßu Viettel (HST Agent).

Nhi·ªám v·ª•: T·ª´ c√¢u h·ªèi ti·∫øng Vi·ªát c·ªßa ng∆∞·ªùi d√πng, h√£y x√°c ƒë·ªãnh ƒê·ªêI T∆Ø·ª¢NG ch√≠nh
cho b√°o c√°o scenario_3, thu·ªôc m·ªôt trong c√°c nh√≥m:

1. ƒê∆°n v·ªã kinh doanh Viettel (ƒêVKD)
   - L∆∞u trong c·ªôt: "ƒê∆°n_v·ªã_kinh_doanh(VTS)"
   - V√≠ d·ª•: "TT CQƒêT", "TT DTTM", "Trung t√¢m mi·ªÅn B·∫Øc", ...

2. T·ªânh / Th√†nh ph·ªë
   - L∆∞u trong c·ªôt: "M√£_t·ªânh_m·ªõi"
   - Gi√° tr·ªã l√† m√£ t·ªânh, v√≠ d·ª•:
     - H√† N·ªôi  -> HNI
     - H·ªì Ch√≠ Minh / TP HCM -> HCM
     - ƒê√† N·∫µng -> DNG
     - H·∫£i Ph√≤ng -> HPG
     - C·∫ßn Th∆° -> CTO
   - N·∫øu kh√¥ng ch·∫Øc m√£ t·ªânh, c√≥ th·ªÉ d√πng t√™n th∆∞·ªùng (kh√¥ng d·∫•u ho·∫∑c c√≥ d·∫•u),
     mi·ªÖn l√† d·ªÖ d√πng ƒë·ªÉ search.

3. Lƒ©nh v·ª±c kh√°ch h√†ng
   - L∆∞u trong c·ªôt: "Lƒ©nh_v·ª±c_Kh√°ch_h√†ng"
   - V√≠ d·ª•: "YTS", "GDS", "CQT", "BQP", "KHDN", ...

H√£y TR·∫¢ V·ªÄ DUY NH·∫§T m·ªôt JSON v·ªõi schema:

{
  "target_name": "string",    // t√™n hi·ªÉn th·ªã cho ng∆∞·ªùi d√πng: "H√† N·ªôi", "TT CQƒêT", "lƒ©nh v·ª±c YTS", ...
  "search_field": "dvkd" | "province" | "field" | "unknown",
  "search_value": "string"    // gi√° tr·ªã d√πng ƒë·ªÉ search (kh√¥ng c·∫ßn th√™m %)
}

QUY T·∫ÆC:
- N·∫øu c√¢u h·ªèi n√≥i r√µ v·ªÅ t·ªânh / th√†nh ph·ªë:
  + V√≠ d·ª•: "H√† N·ªôi", "TP HCM", "ƒê√† N·∫µng", ...
  => search_field = "province"
  => search_value = m√£ t·ªânh (HNI, HCM, DNG, ...) n·∫øu b·∫°n bi·∫øt,
     n·∫øu kh√¥ng bi·∫øt th√¨ d√πng t√™n th∆∞·ªùng (vd: "h√† n·ªôi" ho·∫∑c "ha noi").

- N·∫øu c√¢u h·ªèi n√≥i v·ªÅ ƒêVKD:
  + V√≠ d·ª•: "TT CQƒêT", "trung t√¢m CQƒêT", "ƒêVKD mi·ªÅn Nam", ...
  => search_field = "dvkd"
  => search_value = t√™n/vi·∫øt t·∫Øt ƒêVKD (vd: "tt cqƒët").

- N·∫øu c√¢u h·ªèi n√≥i v·ªÅ lƒ©nh v·ª±c kh√°ch h√†ng:
  + V√≠ d·ª•: "lƒ©nh v·ª±c YTS", "lƒ©nh v·ª±c CQT", "ph√¢n kh√∫c KHDN", ...
  => search_field = "field"
  => search_value = gi√° tr·ªã d√πng trong c·ªôt "Lƒ©nh_v·ª±c_Kh√°ch_h√†ng" (vd: "yts", "cqt", "khdn").

- N·∫øu kh√¥ng x√°c ƒë·ªãnh r√µ ƒë∆∞·ª£c lo·∫°i ƒë·ªëi t∆∞·ª£ng:
  => search_field = "unknown"
  => search_value = t·ª´ kh√≥a quan tr·ªçng nh·∫•t li√™n quan ƒë·∫øn ƒë·ªëi t∆∞·ª£ng,
     ∆∞u ti√™n t·ª´/cuÃ£m t·ª´ ·ªü cu·ªëi c√¢u.

CH·ªà TR·∫¢ V·ªÄ JSON, KH√îNG TH√äM GI·∫¢I TH√çCH.
"""

        try:
            resp = self.client.chat.completions.create(
                model=self.model,
                temperature=0.0,
                max_tokens=256,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": question},
                ],
            )
            content = resp.choices[0].message.content.strip()

            # C·ªë g·∫Øng b√≥c ri√™ng ph·∫ßn JSON n·∫øu model l·ª° n√≥i th√™m
            m = re.search(r"\{.*\}", content, re.DOTALL)
            if m:
                json_str = m.group(0)
            else:
                json_str = content

            data = json.loads(json_str)

            target_name = (data.get("target_name") or "").strip()
            search_field = (data.get("search_field") or "").strip().lower()
            search_value = (data.get("search_value") or "").strip().lower()

        except Exception as e:
            logger.error(f"[PLANNER] LLM extract scenario_3 object failed: {e}")
            # Fallback ƒë∆°n gi·∫£n: l·∫•y t·ª´ cu·ªëi c√πng trong c√¢u h·ªèi
            words = question.split()
            target_name = words[-1] if words else ""
            search_field = "unknown"
            search_value = target_name.lower()

        if not target_name:
            target_name = search_value or "ƒë·ªëi t∆∞·ª£ng"

        if search_field not in {"dvkd", "province", "field", "unknown"}:
            search_field = "unknown"

        # Escape d·∫•u nh√°y ƒë∆°n cho an to√†n SQL
        search_value = search_value.replace("'", "''")

        return target_name, search_field, search_value
    
    def _plan_scenario_3(self, question: str):
        """
        Scenario 3: B√°o c√°o theo ƒë·ªëi t∆∞·ª£ng c·ª• th·ªÉ (ƒêVKD/T·ªânh/Lƒ©nh v·ª±c)

        Tr·∫£ v·ªÅ 4 query:
        - viettel_overall: T·ªïng quan Viettel to√†n th·ªã tr∆∞·ªùng
        - obj_overview: T·ªïng quan ri√™ng cho ƒë·ªëi t∆∞·ª£ng
        - obj_by_month: Gi√° tr·ªã theo th√°ng c·ªßa ƒë·ªëi t∆∞·ª£ng
        - obj_by_month_lk: Gi√° tr·ªã l≈©y k·∫ø theo th√°ng c·ªßa ƒë·ªëi t∆∞·ª£ng
        """

        # 1. Nh·ªù LLM tr√≠ch xu·∫•t ƒë·ªëi t∆∞·ª£ng
        target_name, search_field, raw_search_value = self._extract_scenario3_object_via_llm(question)

        logger.info(
            f"[PLANNER S3] target_name='{target_name}', "
            f"search_field='{search_field}', search_value='{raw_search_value}'"
        )

        # 2. Build WHERE clause d·ª±a tr√™n lo·∫°i ƒë·ªëi t∆∞·ª£ng
        if search_field == "dvkd":
            # ƒê∆°n v·ªã kinh doanh Viettel
            where_clause = (
                f'LOWER("ƒê∆°n_v·ªã_kinh_doanh(VTS)") ILIKE \'%{raw_search_value}%\''
            )
        elif search_field == "province":
            # T·ªânh / Th√†nh ph·ªë (d√πng M√£_t·ªânh_m·ªõi, nh∆∞ng v·∫´n cho ph√©p ILIKE ƒë·ªÉ linh ho·∫°t)
            where_clause = (
                f'LOWER("M√£_t·ªânh_m·ªõi") ILIKE \'%{raw_search_value}%\''
            )
        elif search_field == "field":
            # Lƒ©nh v·ª±c kh√°ch h√†ng
            where_clause = (
                f'LOWER("Lƒ©nh_v·ª±c_Kh√°ch_h√†ng") ILIKE \'%{raw_search_value}%\''
            )
        else:
            # Fallback: t√¨m trong c·∫£ 3 field
            where_clause = f"""(
                LOWER("ƒê∆°n_v·ªã_kinh_doanh(VTS)") ILIKE '%{raw_search_value}%'
                OR LOWER("M√£_t·ªânh_m·ªõi") ILIKE '%{raw_search_value}%'
                OR LOWER("Lƒ©nh_v·ª±c_Kh√°ch_h√†ng") ILIKE '%{raw_search_value}%'
            )"""

        # 3. Tr·∫£ v·ªÅ b·ªô queries gi·ªëng logic c≈© nh∆∞ng kh√¥ng d√πng regex n·ªØa
        return {
            "scenario": "scenario_3",
            "queries": [
                # Query 1: T·ªîNG QUAN VIETTEL TO√ÄN TH·ªä TR∆Ø·ªúNG
                {
                    "id": "viettel_overall",
                    "description": "T·ªïng quan Viettel to√†n th·ªã tr∆∞·ªùng",
                    "sql": """
                        WITH market_total AS (
                            SELECT 
                                SUM("Gi√°_tr√∫ng_th·∫ßu") AS tong_thi_truong
                            FROM thau_2025
                            WHERE "Gi√°_tr√∫ng_th·∫ßu" > 0
                                AND "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" != 'Kh√°c'
                        ),
                        viettel_data AS (
                            SELECT 
                                COUNT(*) AS so_goi,
                                SUM("Gi√°_tr√∫ng_th·∫ßu") AS gia_tri
                            FROM thau_2025
                            WHERE "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" = 'Viettel'
                                AND "Gi√°_tr√∫ng_th·∫ßu" > 0
                        ),
                        vendor_ranking AS (
                            SELECT 
                                "Nh√≥m_tr√∫ng_th·∫ßu_shortlist",
                                SUM("Gi√°_tr√∫ng_th·∫ßu") AS gia_tri,
                                RANK() OVER (ORDER BY SUM("Gi√°_tr√∫ng_th·∫ßu") DESC) AS rank
                            FROM thau_2025
                            WHERE "Gi√°_tr√∫ng_th·∫ßu" > 0
                                AND "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" != 'Kh√°c'
                            GROUP BY "Nh√≥m_tr√∫ng_th·∫ßu_shortlist"
                        )
                        SELECT 
                            vd.so_goi,
                            vd.gia_tri,
                            ROUND(
                                CAST(vd.gia_tri * 100.0 / mt.tong_thi_truong AS NUMERIC),
                                1
                            ) AS share,
                            vr.rank
                        FROM viettel_data vd
                        CROSS JOIN market_total mt
                        LEFT JOIN vendor_ranking vr 
                            ON vr."Nh√≥m_tr√∫ng_th·∫ßu_shortlist" = 'Viettel'
                    """
                },

                # Query 2: T·ªîNG QUAN RI√äNG CHO ƒê·ªêI T∆Ø·ª¢NG
                {
                    "id": "obj_overview",
                    "description": f"T·ªïng quan ri√™ng cho {target_name}",
                    "sql": f"""
                        WITH obj_total AS (
                            SELECT 
                                SUM("Gi√°_tr√∫ng_th·∫ßu") AS tong_obj
                            FROM thau_2025
                            WHERE "Gi√°_tr√∫ng_th·∫ßu" > 0
                                AND "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" != 'Kh√°c'
                                AND {where_clause}
                        ),
                        viettel_obj AS (
                            SELECT 
                                COUNT(*) AS so_goi,
                                SUM("Gi√°_tr√∫ng_th·∫ßu") AS gia_tri
                            FROM thau_2025
                            WHERE "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" = 'Viettel'
                                AND "Gi√°_tr√∫ng_th·∫ßu" > 0
                                AND {where_clause}
                        )
                        SELECT 
                            vo.so_goi,
                            vo.gia_tri,
                            CASE 
                                WHEN ot.tong_obj > 0 THEN 
                                    ROUND(
                                        CAST(vo.gia_tri * 100.0 / ot.tong_obj AS NUMERIC),
                                        1
                                    )
                                ELSE 0
                            END AS share
                        FROM viettel_obj vo
                        CROSS JOIN obj_total ot
                    """
                },

                # Query 3: GI√Å TR·ªä THEO TH√ÅNG C·ª¶A ƒê·ªêI T∆Ø·ª¢NG
                {
                    "id": "obj_by_month",
                    "description": f"Gi√° tr·ªã theo th√°ng c·ªßa {target_name}",
                    "sql": f"""
                        SELECT 
                            EXTRACT(MONTH FROM "Thoi_gian_phe_duyet") AS thang,
                            SUM("Gi√°_tr√∫ng_th·∫ßu") AS gia_tri,
                            COUNT(*) AS so_goi
                        FROM thau_2025
                        WHERE "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" = 'Viettel'
                            AND "Gi√°_tr√∫ng_th·∫ßu" > 0
                            AND {where_clause}
                        GROUP BY thang
                        ORDER BY thang
                    """
                },

                # Query 4: GI√Å TR·ªä L≈®Y K·∫æ THEO TH√ÅNG C·ª¶A ƒê·ªêI T∆Ø·ª¢NG
                {
                    "id": "obj_by_month_lk",
                    "description": f"Gi√° tr·ªã l≈©y k·∫ø theo th√°ng c·ªßa {target_name}",
                    "sql": f"""
                        WITH monthly_data AS (
                            SELECT 
                                EXTRACT(MONTH FROM "Thoi_gian_phe_duyet") AS thang,
                                SUM("Gi√°_tr√∫ng_th·∫ßu") AS gia_tri
                            FROM thau_2025
                            WHERE "Nh√≥m_tr√∫ng_th·∫ßu_shortlist" = 'Viettel'
                                AND "Gi√°_tr√∫ng_th·∫ßu" > 0
                                AND {where_clause}
                            GROUP BY thang
                        )
                        SELECT 
                            thang,
                            SUM(gia_tri) OVER (ORDER BY thang) AS gia_tri_luy_ke
                        FROM monthly_data
                        ORDER BY thang
                    """
                },
            ]
        }
